---
科目: "408"
课程名称: 计算机组成原理
tags: [CPU]
一轮复习情况: 进行中
二轮复习情况: 未开始
三轮复习情况: 未开始
难度:
考频:
备注:
---
# 05 中央处理器
CPU，顾名思义，是计算机的大脑和指挥中心，所有的计算、数据处理和指令执行都离不开它。
 #CPU #中央处理器 #功能结构 #指令执行 #数据通路 #控制器 #中断 #流水线 #多处理器

> [!NOTE] 学习目标 
>  >- (一)CPU 的功能和基本结构
>  > - [[#1. CPU的功能|1. CPU的功能]]
>  > - [[#2. CPU的基本结构|2. CPU的基本结构]]
>  >    - [[#用户可见寄存器|(1) 用户可见寄存器]]
>  >    - [[#用户不可见寄存器|(2) 用户不可见寄存器]]
>  >- (二)指令执行过程
>  > - [[#1. 指令周期|1. 指令周期]]
>  > - [[#2. 指令周期的数据流|2. 指令周期的数据流]]
>  > - [[#3. 指令执行方案|3. 指令执行方案]]
>  >- (三)数据通路的功能和基本结构
>  > - [[#1. 数据通路的功能|1. 数据通路的功能]]
>  > - [[#2. 数据通路的组成|2. 数据通路的组成]]
>  > - [[#3. 数据通路的基本结构|3. 数据通路的基本结构]]
>  >    - [[#单总线结构|(1) 单总线结构]]
>  >    - [[#双总线结构|(2) 双总线结构]]
>  >    - [[#三总线结构|(3) 三总线结构]]
>  > - [[#4. 数据通路的操作举例|4. 数据通路的操作举例]]
>  >- (四)控制器的功能和工作原理 #常考
>  > - [[#1. 控制器的结构和功能|1. 控制器的结构和功能]]
>  > - [[#2. 硬布线控制器|2. 硬布线控制器]]
>  > - [[#3. 微程序控制器|3. 微程序控制器]]
>  >- (五) 异常和中断机制 #2011年
>  > 1. [[#1. 异常和中断的基本概念|异常和中断的基本概念]]
>  > 2. [[#2. 异常和中断的分类|异常和中断的分类]]
>  > 3. [[#3. 异常和中断响应过程|异常和中断的检测与响应]]
>  >- (六)指令流水线 #必考 #2011年
>  > 1. [[#1. 指令流水线的基本概念|指令流水线的基本概念]]
>  > 2. [[#2. 指令流水线的基本实现|指令流水线的基本实现]]
>  > 3. [[#3. 流水线的冒险与处理 (Pipeline Hazards)|结构冒险、数据冒险和控制冒险的处理]]
>  > 4. [[#5. 高级流水线技术|超标量和动态流水线的基本概念]]
>  >- (七)多处理器基本概念 #近年修改
>  > 1. [[#1. SISD、SIMD、MIMD|SISD，SIMD，MIMD、向量处理器的基本概念]]
>  > 2. [[#2. 硬件多线程 (Hardware Multithreading)|硬件多线程的基本概念]]
>  > 3. [[#3. 多核处理器 (Multi-core Processor)|多核处理器（multi-core）的基本概念]]
>  > 4. [[#4. 共享内存多处理器 (Shared-Memory Multiprocessor)|共享内存多处理器（SMP）的基本概念]]
> 
> ---
>  >    *(注：动态流水线概念在“高级流水线技术”中有所涉及，如乱序执行等)*
## [[#05-1 CPU的功能和基本结构|05-1 CPU的功能和基本结构]]

CPU (Central Processing Unit)，中央处理器，是计算机系统的核心部件，负责解释计算机指令以及处理计算机软件中的数据。它就像计算机的"大脑"，所有的计算和控制都由它来完成。

### 1. CPU的功能
CPU主要有以下四大功能：
1. **程序控制**：
    * 按照存储器中的指令序列（程序）逐条取出并执行指令。
    * 控制程序执行的顺序，包括顺序执行、条件跳转、循环等。
    * 通过**程序计数器 (PC)** 和**指令寄存器 (IR)** 来实现。
2. **操作控制**：
    * 对指令进行译码，根据指令的类型和操作数，产生相应的控制信号。
    * 这些控制信号会发送给计算机其他部件，指挥它们完成指令所规定的操作。
    * 例如，在加法指令执行时，控制信号会指示ALU执行加法运算，并指示寄存器将结果写回。
3. **数据加工 (运算处理)**：
    * 执行各种算术运算（加、减、乘、除）和逻辑运算（与、或、非、异或、比较、移位）。
    * 这部分功能主要由**算术逻辑单元 (ALU)** 完成。
4. **数据传输 (信息存储)**：
    * 在CPU内部，实现寄存器之间的数据传输。
    * 在CPU与主存储器之间，进行数据和指令的存取。
    * 在CPU与I/O设备之间，进行数据输入输出。
    * 这部分功能主要通过CPU内部的**寄存器组**和**数据总线**实现。

### 2. CPU的基本结构
CPU通常由以下三个主要部分组成：
![[考研学习笔记02-计算机组成原理 05 中央处理器 2025-10-20 0907CPU的组成.png|503x293]]
1. **运算器 (Arithmetic Logic Unit, ALU)**： #2020年
    * **功能**：负责执行所有的算术运算（加、减、乘、除）和逻辑运算（与、或、非、异或、比较、移位等）。它是CPU进行数据加工的核心部件。
    * **组成**：
        * **算术逻辑单元**：实现算术和逻辑运算。
        * **累加寄存器 (AC)**：暂时存放ALU运算的结果或操作数（现代CPU中通常由通用寄存器代替其作用）。
        * **数据缓冲寄存器 (DR/MBR)**：在CPU与内存之间进行数据传输时，作为数据缓冲区。
        * **状态条件寄存器 (PSW/FLAGS)**：存放运算过程中产生的各种状态信息和条件码（如溢出、零、负、进位等），用于控制指令的执行（如条件跳转）。

>[!key] **ALU与机器字长关系** #2020年
>*   **机器字长**：CPU一次整数运算所能处理的二进制数据位数，反映了数据通路宽度和运算精度。
>*   **ALU位数**：作为执行定点整数运算的核心部件，其位数必须与**机器字长**严格一致。ALU的设计直接体现机器字长定义，负责处理与字长相匹配的算术和逻辑操作。
>*   **ALU功能与控制**：ALU的运算数和结果位数通常与计算机的机器字长相同，控制信号选择ALU执行的功能。

2. **控制器 (Control Unit, CU)**： #2025年
    * **功能**：CPU的指挥中心，负责**解释指令**、**协调**并**控制**计算机各部件的运行。它按照预定顺序，向各部件发出相应的控制信号，使它们按时、按序、协调工作。
    * **组成**：
        * **程序计数器 (Program Counter, PC)**：存储**下一条要执行的指令的地址**。每执行一条指令，PC的值会自动加1（或根据跳转指令修改）。它是程序能够顺序执行的关键。
        * **指令寄存器 (Instruction Register, IR)**：存储**当前正在执行的指令**。从内存中取出的指令首先存放在IR中。
        * **指令译码器 (Instruction Decoder)**：对IR中指令的操作码部分进行译码，解释指令的含义，生成相应的控制信号。
        * **时序部件 (Timing Unit)**：提供各种时序信号，控制指令执行的各个阶段（如取指、译码、执行）的时序。
        * **主存储器地址寄存器 (MAR)**：存放要访问的内存单元的地址。
        * **主存储器数据寄存器 (MDR)**：存放从内存中读取的数据或将要写入内存的数据。
>[!danger] **PC不属于通用寄存器组** #2025年
>*   **程序计数器(PC)** 属于**专用寄存器**而非通用寄存器组成员。
>*   **通用寄存器组** (`GPRs`) 专门用于存储程序操作数，支持程序员通过汇编指令直接寻址访问。
>*   **PC作为指令地址寄存器**，具有专用特性：
>	*   **硬件自动管理**：在取指周期自动递增。
>	*   **间接访问方式**：仅通过跳转指令(`JMP`, `CALL`)间接修改。
>	*   **系统级功能**：属于处理器状态管理范畴。

>[!key] **控制器与指令操作码译码** #2025年
    >*   控制器中**一定包含指令操作码的译码电路**。这是指令执行的基础设施。
    >*   无论采用硬布线控制还是微程序控制方式，都需要将 `n` 位操作码转换为 `2ⁿ` 个控制信号的组合逻辑或微指令地址。

3. **寄存器组 (Registers)**： #2010年 #2016年 #2020年 #2021年
    * **功能**：CPU内部高速、容量小但速度极快的存储设备。用于临时存放程序执行过程中的各种数据和状态信息。
    * **特点**：
        * **速度快**：直接与ALU和CU相连，访问速度远超主存。
        * **容量小**：数量有限（通常几十到几百个）。
        * **CPU与内存通信的桥梁**：大多数操作都在寄存器之间进行，减少对慢速内存的访问。
>[!tip] **寄存器类型与程序员可见性** #2010年 #2021年
    >*   **程序员可见性**：汇编语言程序员能否直接访问和操作某个寄存器。
    >*   **可见寄存器**：属于**指令集架构 (ISA) 层面**的资源，程序员可通过汇编指令直接访问和操作。
    >*   **不可见寄存器**：属于 **CPU 内部微架构实现细节**，由硬件自动管理，对程序员透明。
>
>    | 寄存器类型          | 英文缩写 | 程序员可见性 | 访问层次     | 功能描述                                   |
>    | :------------------ | :------- | :----------- | :----------- | :----------------------------------------- |
>    | **程序计数器**      | PC       | 可见         | ISA 层       | 存储下一条待执行指令地址                 |
>    | **程序状态字/标志** | PSW/FLAGS | 可见         | ISA 层       | 存储处理器状态标志位 (条件码、中断使能等)  |
>    | **通用寄存器组**    | GPRs     | 可见         | ISA 层       | 数据存储与运算操作                       |
>    | **基址寄存器**      | BR       | 可见         | ISA 层       | 存储内存基地址 (支持灵活内存寻址)        |
>    | **存储器地址寄存器** | MAR      | 不可见       | 微架构层     | CPU 内部地址传输 (由硬件自动管理)        |
>    | **存储器数据寄存器** | MDR      | 不可见       | 微架构层     | CPU 内部数据传输 (由硬件自动管理)        |
>    | **指令寄存器**      | IR       | 不可见       | 微架构层     | 存储当前执行指令 (取指周期自动加载)      |
>    | **微指令寄存器**    | μIR      | 不可见       | 微程序层     | 存储微指令控制信号 (更低层次的硬件控制) |

#### (1) 用户可见寄存器
(User-Visible Registers)
程序员可以通过指令直接访问和操作这些寄存器，主要用于存储数据、地址和索引等。
*   **通用寄存器 (General-Purpose Registers, GPRs)**： #2020年
    *   数量最多，功能灵活，可用于存放操作数（数据）、地址、中间结果等。
    * 例如：`AX, BX, CX, DX` (16位系统) 或 `EAX, EBX, ECX, EDX` (32位系统) 或 `RAX, RBX, RCX, RDX` (64位系统)。
    *   **与机器字长关系**：通用寄存器位数必须与**机器字长**一致，以保证数据通路宽度匹配和数据传输效率。
*   **状态字寄存器 / 程序状态字寄存器 (Program Status Word, PSW) / 标志寄存器 (FLAGS)**： #2011年 #2021年
    *   **作用**：存放当前程序运行的各种**状态信息和条件码**。
    *   例如：#标志位
        *   **零标志 (ZF)**：运算结果为0时置1。
        *   **符号标志 (SF)**：运算结果为负数时置1。
        *   **进位标志 (CF)**：有符号数运算时最高位产生进位或借位时置1。
        *   **溢出标志 (OF)**：有符号数运算结果溢出时置1。
        *   **中断允许标志 (IF)**：控制是否响应中断请求。
    *   这些标志位在条件跳转指令（如 `JZ`、`JNZ`）中被广泛使用。
>[!key] **无符号整数条件转移指令 (`bgt`) 转移条件** #2011年
>*   对于无符号整数比较 `A > B`，处理器通过执行减法运算 `A - B` 来设置标志位。
>*   **条件分解**：
>	*   `A > B` 成立条件： `A - B > 0` (即减法运算**既无借位又非零**)。
>*   **标志位状态**：
>	*   `CF = 0`：无借位发生，表明 `A ≥ B`。
>	*   `ZF = 0`：结果非零，表明 `A ≠ B`。
>	*   **组合条件**：`CF = 0` 且 `ZF = 0`。
>*   **布尔表达式推导**：
>	1.  目标条件： $\overline{CF} \cdot \overline{ZF} = 1$
>	2.  应用德摩根律： $\overline{CF} \cdot \overline{ZF} = \overline{CF + ZF}$
>	3.  因此转移条件为： $\overline{CF + ZF} = 1$。
*   **程序计数器 (Program Counter, PC)**： #2016年
    *   **作用**：存放**下一条要执行的指令在主存储器中的地址**。
    *   它是CPU执行程序的核心，控制着指令的顺序执行。

>[!key] **PC 位数计算** #2016年
>*   **计算依据**：最大可寻址指令数量。
>*   **计算公式**：$\text{log}_2(\text{总指令数})$。
>*   **字边界对齐影响**：如果指令按**字边界对齐存放**，指令地址的最低位（取决于字长）固定为 `0`，PC 实际只需要存储高位地址。
>	*   例如：32 位字长（4 字节），字对齐意味着地址是 4 的倍数，最低 2 位为 `00`。此时，PC 位数只需 $\text{log}_2(\text{总字节数} / 4)$。

>[!info] **PC 自动递增** #2011年
>*   即使是空操作指令 (`NOP`)，在取指阶段完成后，程序计数器 `PC` 也会自动递增指向下一条指令地址，因此 `PC` 寄存器内容会发生改变。

*   **数据寄存器 (Data Registers)**：
    *   专门用于保存操作数或运算结果。通常通用寄存器也兼具此功能。
*   **地址寄存器 (Address Registers)**：
    *   专门用于保存内存地址，例如基地址寄存器、变址寄存器。
*   **段寄存器 (Segment Registers)** (在某些体系结构如x86中)：
    *   用于存储段的起始地址，配合偏移地址形成物理地址。例如 `CS` (代码段)、`DS` (数据段)、`SS` (堆栈段)、`ES` (附加段) 等。

#### (2) 用户不可见寄存器
(Control and Status Registers)
这些寄存器由CPU内部使用，用于控制CPU的操作或反映CPU的状态。程序员通常不能直接访问，而是通过特殊指令或间接方式影响它们。
*   **指令寄存器 (Instruction Register, IR)**： #2016年 #2021年
    *   **作用**：存放**当前正在执行的指令**。
    *   指令从内存中取到CPU后，首先进入IR。
>[!key] **IR 位数计算** #2016年
    >*   **计算依据**：指令字长度。
    >*   **计算公式**：等于指令字位数。IR 必须能够完整存储一条指令的全部信息。
    >*   **与机器字长关系**：IR 的位数取决于**指令字长**而非机器字长。指令字长是指令集架构的独立设计参数，可以与机器字长不同。
*   **内存地址寄存器 (Memory Address Register, MAR)**： #2010年
    *   **作用**：存放CPU当前要访问的**内存单元的地址**。
    *   它的内容直接送到地址总线。
*   **内存数据寄存器 (Memory Data Register, MDR)**： #2010年
    *   **作用**：存放CPU与内存之间**传输的数据或指令**。
    *   它的内容直接与数据总线进行双向传输。

---
## [[#05-2 指令执行过程|05-2 指令执行过程]]
CPU执行程序就是逐条执行指令的过程。每条指令的执行都遵循一个固定的生命周期，通常包括取指、译码、执行、访存和写回等阶段。

### 1. 指令周期
(Instruction Cycle) #2011年
**指令周期**是指CPU从主存储器中取出并执行一条指令所需要的全部时间。一个指令周期包含多个**机器周期 (Machine Cycle)**（或称为CPU周期）。每个机器周期又包含若干个**时钟周期 (Clock Cycle)**（或称为节拍脉冲）。
*   **指令周期与时钟周期的关系**：每个指令周期**一定大于或等于一个CPU时钟周期**。时钟周期是CPU工作的基本时间单位，指令周期作为完成一条指令执行的时间，必然大于或等于一个时钟周期。 #2011年

一条指令的执行过程通常可分解为以下几个阶段：
1.  **取指周期 (Fetch Cycle)**：
    *   **任务**：从内存中取出指令。
    *   **过程**：
        1.  根据 `PC` 中的地址，从内存中读取指令字。
        2.  将读取的指令字存入 `IR`。
        3.  更新 `PC` (通常 `PC = PC + 1`，指向下一条指令的地址)。
>[!key] **取指操作与内存访问** #2011年
    >*   在**不采用 Cache 和指令预取技术**的情况下，每个指令周期都需要执行取指操作，因此**CPU 都至少访问内存一次**。
2.  **译码周期 (Decode Cycle)**：
    *   **任务**：分析指令，识别操作码和操作数。
    *   **过程**：
        1.  `IR` 中的指令被送到指令译码器。
        2.  指令译码器对操作码进行译码，确定指令的操作类型。
        3.  根据指令的寻址方式，计算操作数的有效地址。
3.  **执行周期 (Execute Cycle)**：
    *   **任务**：执行指令规定的操作（如算术逻辑运算）。
    *   **过程**：
        1.  根据译码结果和有效地址，从寄存器或内存中取出操作数。
        2.  ALU对操作数进行运算。
        3.  将运算结果存回寄存器或临时存储器。
    *   对于简单的指令（如寄存器-寄存器操作），可能不需要访存。

4.  **访存周期 (Memory Cycle / Access Cycle)** (可选)：
    *   **任务**：如果指令需要访问内存（如数据读取 `Load` 或数据写入 `Store`），则执行此阶段。
    *   **过程**：
        1.  将要访问的内存地址送入 `MAR`。
        2.  根据是读操作还是写操作，通过数据总线从内存读取数据到 `MDR`，或将数据从 `MDR` 写入内存。
5.  **写回周期 (Write-back Cycle)** (可选)：
    *   **任务**：将指令执行的结果写回到目标位置（通常是寄存器）。
    *   **过程**：
        1.  将执行结果（可能在ALU的输出或MDR中）写入到指定的通用寄存器。
    *   并非所有指令都需要写回，例如"存"指令（Store）的结果是写到内存，而不是写回CPU内部寄存器。

> [!NOTE] 现代CPU的流水线 (Pipeline) 技术
> 在现代高性能CPU中，上述指令周期中的各个阶段并不是串行独立执行的。通过**指令流水线技术**，不同的指令可以同时在不同的阶段执行，大大提高了CPU的吞吐量。这部分内容我们会在 [[#05-6 指令流水线|05-6 指令流水线]] 中详细讲解。

### 2. 指令周期的数据流

让我们以一个简单的指令 `ADD R1, R2` (将R2内容加到R1，结果存回R1) 为例，来看看数据如何在CPU内部流动：
1.  **取指阶段**：
    *   `PC` 内容送入 `MAR`。
    *   通过地址总线，`MAR` 地址送到内存，CPU发起读操作。
    *   内存将 `PC` 地址处的指令字通过数据总线送到 `MDR`。
    *   `MDR` 内容送入 `IR`。
    *   `PC` 内容自动加1。
2.  **译码阶段**：
    *   `IR` 中的操作码部分送到指令译码器，译码器识别出是 `ADD` 指令。
    *   从 `IR` 中取出操作数地址 (这里是 `R1` 和 `R2` 的寄存器编号)。
3.  **执行阶段**：
    *   根据译码器发出的控制信号：
        *   `R1` 寄存器内容送入 `ALU` 的一个输入端。
        *   `R2` 寄存器内容送入 `ALU` 的另一个输入端。
        *   `ALU` 执行加法运算。
        *   运算结果（例如，暂存在一个临时寄存器中）。
4.  **写回阶段**：
    *   `ALU` 的运算结果通过内部总线，送回 `R1` 寄存器。

### 3. 指令执行方案
指令执行方案涉及到CPU如何控制指令的执行流程。主要有两种方法：

1.  **单周期处理器 (Single-Cycle Processor)**： #2016年
    *   **概念定义**：所有指令都在一个时钟周期内完成执行的处理器架构。
    *   **优点**：控制逻辑简单。
    *   **缺点**：
        *   **时钟周期长**：时钟周期必须足够长，以适应最复杂、最耗时的指令。导致简单的指令也需要等待很长时间才能完成，效率低下。
        *   **低时钟频率**：处理器的时钟频率较低。
        *   **数据通路复杂**：需要多路径并行数据传输，无法采用单总线结构数据通路，否则会因总线冲突和性能瓶颈无法满足并行数据传输需求。
    *   **特点**：
        *   `CPI = 1`。
        *   在指令执行过程中控制信号不变。
        *   实际应用中很少见。
2.  **多周期处理器 (Multi-Cycle Processor)**：
    *   **概念定义**：每条指令的执行被划分为多个阶段（如取指、译码、执行、访存、写回），每个阶段在一个时钟周期内完成。
    *   **优点**：
        *   时钟周期可以很短，由最快的阶段决定。
        *   不同复杂度的指令可以占用不同数量的时钟周期。
        *   硬件资源（如ALU、存储器端口）可以在不同阶段复用，节省硬件开销。
    *   **缺点**：控制逻辑相对复杂，需要状态机来控制。
    *   这是目前大多数CPU的基本实现方式，也是实现流水线的基础。
    *   **特点**：`CPI > 1`。
3.  **指令流水线处理器 (Pipelined Processor)**：
    *   **概念定义**：基于多周期处理器的思想，但进一步优化。
    *   通过将指令的执行过程分解为更小的阶段，并让多条指令在不同阶段**并行**执行，从而提高指令的吞吐率。
    *   **优点**：大幅提高CPU的性能和吞吐量。
    *   **缺点**：引入了流水线冒险（如数据冒险、控制冒险、结构冒险），需要额外的硬件和软件机制来处理。这将在 [[#05-6.3 流水线的冒险与处理 (Pipeline Hazards)|05-6.3 指令流水线的冒险与处理]] 中详细讨论。
    *   **特点**：在稳态情况下，理想 `CPI = 1`。

---
## [[#05-3 数据通路的功能和基本结构|05-3 数据通路的功能和基本结构]]
**数据通路 (Datapath)** 是指CPU中数据流经的硬件路径，包括功能部件（如ALU、寄存器）以及它们之间进行数据传输的连接线路（总线）。它负责数据的传输和处理。

### 1. 数据通路的功能
1.  **数据传输**：在CPU内部的寄存器之间、寄存器与ALU之间、寄存器与内存之间传输数据。
2.  **数据处理**：在ALU中进行算术逻辑运算。
3.  **地址形成**：形成内存访问的物理地址。

### 2. 数据通路的组成
#2021年 #2023年
数据通路是CPU中负责数据处理和传输的核心部件。
1.  **操作元件 (组合逻辑元件)**： #2021年 #2023年
    *   **概念定义**：执行算术逻辑运算等数据变换功能。
    *   **逻辑特性**：纯组合逻辑，输出仅依赖当前输入，**无记忆功能**。
    *   **典型实例**：
        *   `ALU` (算术逻辑单元)：执行算术运算和逻辑运算。
        *   `多路选择器 (Multiplexer, MUX)`：根据控制信号选择一路输入到输出。用于在多个数据源中选择一个作为ALU的输入或寄存器的写入数据。
        *   `译码器`
        *   `加法器`
        *   `三态门 (Tri-state Buffer)`：控制数据是否能通过总线。
2.  **状态元件 (时序逻辑元件)**： #2021年 #2023年
    *   **概念定义**：存储数据和状态信息，提供数据存储能力。
    *   **逻辑特性**：时序逻辑，具有**记忆功能**，在时钟边沿触发下更新状态。
    *   **典型实例**：
        *   **寄存器组**：包括通用寄存器、`IR`、`PC`、`MAR`、`MDR` 等，存储操作数和中间结果。
        *   **程序计数器 (PC)**：维护指令地址。
        *   **指令寄存器 (IR)**：保存当前指令。
        *   **计数器**
        *   **存储器**
3.  **互连网络 (传输元件)**：连接各个部件，用于数据传输。可以是单总线、双总线或多总线结构。
4.  **异常事件检测电路 (监控元件)**： #2021年
    *   **概念定义**：检测异常事件并响应。
    *   **关键特性**：数据通路**必须包含**异常事件检测电路，这是现代处理器设计的基本要求。
    *   **典型实例**：
        *   **溢出检测电路**：监控 `ALU` 运算结果是否超出表示范围。
        *   **除零检测逻辑**：在除法运算前检查除数是否为零。
        *   **奇偶校验电路**：检测数据传输中的单 bit 错误。
        *   **边界检查单元**：验证内存访问地址的合法性。
>[!danger] **数据通路包含异常检测电路** #2021年
>*   **数据通路****包含用于异常事件检测及响应的电路**。这是**正确的**叙述。
>*   题目中“数据通路不包含用于异常事件检测及响应的电路”是**错误的**。

### 3. 数据通路的基本结构
数据通路设计没有唯一的标准，但常见的结构有单总线、双总线和三总线结构。
*   **数据流控制**：数据通路的**数据流动路径由控制信号进行控制**。控制器根据指令操作码生成控制信号，这些控制信号决定了数据在通路中的流动方向和处理方式，实现了不同指令的数据路径配置。 #2021年

#### (1) 单总线结构
*   所有功能部件都连接到一条公共的内部总线上。
*   **优点**：结构简单，布线容易，节省硬件。
*   **缺点**：所有数据传输都要通过这条总线，会导致**总线冲突**和**传输瓶颈**，在每个时钟周期内只能完成一次数据传输，效率较低。

#### (2) 双总线结构
*   通常有两条独立的内部总线，可以实现两个数据源同时传输到目的地。
*   例如，两条总线分别作为ALU的两个输入端，可以同时取两个操作数，提高ALU的利用率。
*   **优点**：提高了数据传输并行性，效率高于单总线。
*   **缺点**：结构比单总线复杂。

#### (3) 三总线结构
*   有三条独立的内部总线。例如，两条作为ALU输入，一条作为ALU输出。
*   **优点**：数据传输并行性更高，效率进一步提高。
*   **缺点**：结构最复杂，布线困难，成本高。

> [!NOTE] CPU与内存之间的总线
> 上述讨论的是CPU内部总线。CPU与内存之间通过**系统总线**（包括地址总线、数据总线、控制总线）连接。

### 4. 数据通路的操作举例
以 `R3 <R1 + R2` (将寄存器R1和R2的内容相加，结果存入R3) 为例，在单总线数据通路中的操作序列：
1.  `R1 -> ALU`：将R1的内容通过总线送到ALU的一个输入端（需要一个锁存器暂存）。
2.  `R2 -> ALU`：将R2的内容通过总线送到ALU的另一个输入端（需要一个锁存器暂存）。
3.  `ALU` 执行加法操作。
4.  `ALU -> R3`：ALU的输出结果通过总线送回R3。

这个例子需要至少3个总线传输周期才能完成。如果采用双总线或三总线结构，可以大大缩短这个时间。

---
## 05-4 控制器的功能和工作原理
**控制器 (Control Unit, CU)** 是CPU的核心部件，负责发布指令执行所需的全部控制信号，从而控制整个计算机系统（包括CPU内部和外部设备）协调工作。

### 1. 控制器的结构和功能
*   **功能**：
    1.  **取指令**：从内存中取出指令。
    2.  **分析指令 (译码)**：对指令操作码进行译码，确定操作性质和操作数。
    3.  **执行指令**：根据指令要求，向有关部件发出操作命令（控制信号）。
    4.  **控制协调**：控制CPU内部各部件以及外部设备之间的时序和操作。
*   **组成**：
    *   **指令寄存器 (IR)**
    *   **指令译码器 (ID)**
    *   **时序逻辑**
    *   **微操作信号发生器** (Hardwired CU) 或 **控制存储器** (Microprogrammed CU)
    *   **中断机构**
>[!key] **主存储器 (MM) 与控制存储器 (CS) 对比** #2017年
>*   **主存储器 (MM)**：
> *   **物理位置**：在 CPU **外部**。
> *   **存储内容**：机器指令和数据。
> *   **访问方式**：按**地址访问**（通过地址译码器选择单元）。
> *   **实现技术**：通常由 `RAM` (可读写) 和 `ROM` (只读，用于存放引导程序) 组成。
>*   **控制存储器 (CS)**：
> *   **物理位置**：在 CPU **内部**，是微程序控制器的组成部分。
> *   **存储内容**：微指令序列。
> *   **访问方式**：按**地址访问**（通过微地址寄存器 `μAR` 提供地址）。
> *   **实现技术**：通常由 `ROM` 实现 (因为微指令在系统运行时只需读取)。

>[!danger] **MM和CS都是按地址访问** #2017年
>*   **主存储器和控制存储器**均采用**按地址访问**方式。
>*   **按内容访问 (CAM)** 是一种特殊存储技术，主要应用于相联 Cache、TLB 等需要并行匹配的场合，**并非常规主存或控制存储器**的访问方式。

### 2. 硬布线控制器
(Hardwired Controller) #2009年
*   **工作原理**：通过**组合逻辑电路**来实现控制信号的生成。每条机器指令的操作码直接对应一套固定的逻辑电路，当指令译码后，相应的电路被激活，产生一系列控制信号。
*   **特点**：
    *   **速度快**：控制信号的生成是组合逻辑的，从指令操作码到控制信号输出仅需一个组合逻辑延迟，无需额外的存储器访问，实现了最短的控制路径。
    *   **设计复杂**：对于复杂的指令集，逻辑电路非常庞大和复杂，设计和修改困难。
    *   **缺乏灵活性**：一旦设计完成，控制逻辑以物理电路形式实现，指令集就固定了，很难添加新指令或修改指令功能。
*   **适用场景**：精简指令集计算机 (RISC) 倾向于使用硬布线控制器，因为RISC指令集简单，固定长度，易于译码和快速执行。

### 3. 微程序控制器
(Microprogrammed Controller) #2009年 #2012年 #2014年
*   **工作原理**：将每条机器指令的执行过程，用一系列更基本的**微指令 (Microinstruction)** 组成的微程序来实现。这些微指令存储在CPU内部的一个特殊存储器——**控制存储器 (Control Memory, CM)** 中。
*   **微指令**：
    *   是比机器指令更低层次的指令，直接控制数据通路中的微操作（如寄存器之间的数据传输、ALU操作等）。
    *   一条机器指令对应一个微程序。
    *   微指令通常包括：**微操作控制字段**（指定要执行的微操作）和**下地址字段**（指定下一条微指令的地址）。
*   **微指令的地址确定方法**： #2014年
    *   **断定法 (下地址字段法)**：
        *   **概念定义**：每条微指令的下地址字段直接给出下一条微指令的地址。
        *   **特点**：最灵活的地址确定方式，支持任意的跳转和分支操作。
        *   **位数计算**：下地址字段位数必须能够寻址控制存储器中的**任意一条微指令**。所需位数 = $\lceil \text{log}_2(\text{总微指令数}) \rceil$。
    *   **顺序法**：微地址寄存器 `μAR` 自动加1。
    *   **分支法**：根据条件判断选择地址。
    *   **子程序法**：微地址栈保存返回地址。
*   **执行过程**：
    1.  取出的机器指令的操作码作为微程序的入口地址。
    2.  从控制存储器中读出第一条微指令。
    3.  执行这条微指令指定的微操作，并根据下地址字段或微程序计数器 (μPC) 找到下一条微指令的地址。
    4.  重复上述过程，直到该机器指令对应的所有微指令执行完毕。
*   **特点**：
    *   **灵活性强**：修改微程序即可改变指令功能，易于添加新指令或改变指令集。
    *   **设计简单**：相对于硬布线，设计和调试更容易。
    *   **速度较慢**：需要访问控制存储器，引入了访存延迟。
    *   **兼容性好**：可以通过修改微程序来模拟其他机器的指令集。
*   **适用场景**：复杂指令集计算机 (CISC) 倾向于使用微程序控制器，因为CISC指令集复杂，变长指令，微程序化更易于实现。

**微程序控制器设计技巧**
>[!key] **微指令操作控制字段编码** #2012年
>*   **字段直接编码法**：将所有微命令按照互斥性原则划分为若干个字段，每个字段独立编码。
>*   **互斥性微命令**：指在同一微指令执行周期内不能同时有效的微命令。
>*   **编码设计要求**：
> *   每个互斥类字段必须预留一个编码状态表示**“无操作”**（即该字段在当前微指令中不发出任何微命令）。
> *   对于包含 `n_i` 个微命令的第 `i` 个互斥类，需要编码的状态总数为 `(n_i + 1)`。
> *   每个字段所需的最少位数为 $\lceil \text{log}_2(n_i+1) \rceil$。
> *   操作控制字段总位数 = 各字段位数之和。

>[!key] **微指令下地址字段位数计算** #2014年
>*   **微程序组织**：
> *   **公共微程序**：所有指令执行的共同前序步骤 (如取指微程序)。
> *   **指令微程序**：每条机器指令对应的执行微程序。
>*   **总微指令数**：控制存储器需要存储的微指令总数 = 公共微指令数 + 指令数 $\times$ 平均每条指令微指令数。
>*   **下地址字段位数**：采用断定法时，下地址字段必须能够寻址控制存储器中的**任意一条微指令**。
> *   所需位数 = $\lceil \text{log}_2(\text{总微指令数}) \rceil$。

| 特点         | 硬布线控制器                                 | 微程序控制器                                 |
| :----------- | :------------------------------------------- | :------------------------------------------- |
| **实现方式** | 组合逻辑电路                                 | 微程序 (存储在控制存储器中)                  |
| **控制信号** | 直接由逻辑电路生成                           | 由微指令的微操作字段决定，从控制存储器读出   |
| **速度**     | 快 (组合逻辑)                                | 较慢 (需要访存CM)                            |
| **灵活性**   | 差 (难修改和扩展)                            | 好 (易修改和扩展)                            |
| **设计难度** | 高 (复杂指令集)                              | 低 (结构化，相对简单)                        |
| **应用**     | RISC (精简指令集)                            | CISC (复杂指令集)                            |

---
## 05-5 异常和中断机制
在程序执行过程中，可能会发生一些非预期的事件，它们需要CPU暂停当前任务，转而去处理这些事件。这些事件就是**异常**和**中断**。

### 1. 异常和中断的基本概念
*   **中断 (Interrupt)**： #2009年 #2016年 #2020年 #2025年
    *   **定义**：计算机在执行现行程序的过程中，出现某些**急需处理的异常情况或特殊请求**（通常是来自CPU**外部**的事件），CPU暂时中止现行程序的执行，转而去对这些异常情况或特殊请求进行处理。
    *   **同步性**：是**异步的**，与CPU当前执行的指令无关，随时可能发生。
    *   **可屏蔽性**：是**可屏蔽的**（通常），即CPU可以决定是否响应某些中断请求（通过PSW的IF位）。
    *   **产生源**：**外部设备**（I/O设备、定时器、电源故障等）通过硬件信号线(`IRQ/NMI`)通知CPU。
    *   **处理后返回点**：通常返回到**被中断指令的下一条指令**。
    *   **典型实例**：
        *   `I/O 完成中断` (如 `DMA 传送结束`)。
        *   `定时器到时` (时钟中断)。
        *   `键盘输入` (键盘控制器向CPU发送信号)。
        *   `网络数据包到达` (NIC接收数据包后通知CPU)。
        *   `打印机缺纸`。
*   **异常 (Exception)**： #2016年 #2020年 #2021年
    *   **定义**：CPU在执行程序的过程中，**由当前正在执行的指令**所引起的事件，导致CPU暂停正常执行流程。
    *   **同步性**：是**同步的**，总是与某条特定的指令相关联，并且在执行该指令时发生。
    *   **可屏蔽性**：是**不可屏蔽的**，一旦发生，CPU必须立即处理。
    *   **产生源**：**CPU内部事件**（由当前指令执行引起）通过内部检测机制触发。
    *   **处理后返回点**：往往回到**引起异常的指令处重新执行**（故障）或**该指令的指令的下一条指令**（陷阱）。
    *   **典型实例**：
        *   `整数除以 0`。
        *   `浮点运算下溢`。
        *   `访存缺页` (缺页故障)。
        *   `非法指令`。
        *   `存储保护错`。
        *   `自陷 (Trap)`：如 `系统调用`、`执行断点指令`。
*   **联系与区别**：

| 特性         | 中断 (Interrupt)                         | 异常 (Exception)                             |
| :--------- | :------------------------------------- | :----------------------------------------- |
| **发生源**    | **外部事件**（I/O设备、定时器、电源故障等）| **CPU内部事件**（由当前指令执行引起）|
| **同步性**    | **异步的**：与CPU当前正在执行的指令无关，随时可能发生         | **同步的**：总是与某条特定的指令相关联，在该指令执行时发生            |
| **可屏蔽性**   | **通常可屏蔽**：CPU可以设置是否响应某些中断请求（通过PSW的IF位）| **不可屏蔽**：一旦发生，CPU必须立即处理（如除零错误）|
| **处理后返回点** | 通常返回到**被中断指令的下一条指令**                   | 往往回到**引起异常的指令处重新执行**（故障）或**该指令的下一条指令**（陷阱）|
*   **中断源**：能够发出中断请求的设备或事件。
*   **中断请求标记触发器 (INTR)**：每个中断源都设置一个中断请求标记触发器。当其状态为"1"时，表示中断源有中断请求。
*   **中断请求标记寄存器**：这些触发器可以组成一个寄存器，集中在CPU中或分散在各个中断源中。
*   **外部中断**：CPU会在统一的时刻（通常是**每条指令执行阶段结束前**）向接口发出中断查询信号，以获取I/O的中断请求。
*   **IF标志位**：位于CPU的**程序状态字寄存器 (PSW) / 标志寄存器 (FLAGS)** 中。
    *   `IF = 1`：表示开中断（允许响应可屏蔽中断）。
    *   `IF = 0`：表示关中断（不允许响应可屏蔽中断）。
    *   **关中断的作用**：实现原子操作（一段不希望被中断打断的代码）。

### 2. 异常和中断的分类
#### (1) 中断的分类
#2009年
根据中断源的不同：
*   **外部中断**：
    *   **I/O设备中断**：如硬盘完成数据传输、键盘输入等。
    *   **时钟中断**：定时器产生，用于操作系统的时间片调度。
    *   **硬件故障中断**：如电源掉电、内存错误等。
*   **内部中断 (也常归类到异常)**：
    *   **软件中断 (软中断)**：通过执行一条特殊指令（如 `INT` 指令）由软件主动触发，用于系统调用或调试。

按可屏蔽性分类：
1.  **非屏蔽中断 (Non-Maskable Interrupt, NMI)**：
    *   优先级最高，即使在关中断状态下也会被CPU响应和处理。
    *   通常用于处理**紧急且致命**的事件，如电源掉电。
2.  **可屏蔽中断 (Maskable Interrupt)**：
    *   大多数中断都是可屏蔽中断。
    *   CPU可以通过设置**中断允许标志 (IF)** 来决定是否响应这类中断请求。

#### (2) 异常的分类
#2015年 #2020年 #2021年
根据异常的性质和处理方式：
*   **故障 (Fault)**：
    *   **概念定义**：在指令执行**前**被检测到，且可以**被修复**的错误。
    *   **同步性**：同步。
    *   **可预见性**：意外发生。
    *   **返回行为**：修复后通常会**重新执行该指令**。
    *   **示例**：
        *   **缺页故障 (Page Fault)**：程序访问的页面不在内存，OS将其调入后，重新执行引起缺页的访存指令。
        *   **段违例**。
*   **陷阱 (Trap)** (也称**自陷**)： #2020年
    *   **概念定义**：在指令执行**后**被检测到，**不能被修复**，通常是有意设定的异常事件。其目的是为了**切换到操作系统**执行一些服务（如系统调用）。
    *   **同步性**：同步。
    *   **可预见性**：有意设定。
    *   **返回行为**：完成系统调用后返回到**下一条指令继续执行**。
    *   **示例**：
        *   **除零错误**。
        *   **系统调用 (System Call)**：通过执行特殊指令（如 `INT`、`SYSCALL`）由软件主动触发。这是程序调试机制的核心技术，调试器通过在目标地址插入陷阱指令实现断点功能。
        *   **断点调试**。
*   **中止 (Abort)**：
    *   **概念定义**：发生**严重错误**，导致程序无法恢复，通常会**终止程序**。
    *   **同步性**：同步。
    *   **可预见性**：意外发生。
    *   **返回行为**：发生致命错误，**不返回**，直接终止程序。
    *   **示例**：硬件故障、内存校验错误、双重故障。

### 3. 异常和中断响应过程
#### 1) 响应中断条件
CPU响应中断必须同时满足以下3个条件：
1.  **中断源有中断请求**：对应的中断请求标记触发器为1。
2.  **CPU允许中断**：CPU处于**开中断**状态 (`IF = 1`)。
3.  **一条指令执行完毕**：CPU必须在完成当前指令的执行后才能响应中断，以确保程序状态的完整性，且没有更紧迫的任务（如更高级别的中断或DMA请求）

#### 2) 中断判优
#2011年
当有多个中断源同时提出中断请求时，CPU需要根据一定的**优先级**来确定响应哪个中断源，这个过程称为**中断判优**。
*   **实现方式**：
    1.  **硬件实现**：通过**硬件排队器**实现。排队器既可以设置在CPU中，也可以分散在各个中断源中。
    2.  **软件实现**：通过**查询程序**（在中断服务程序开头）来逐一判断是哪个设备发出的中断。
*   **优先级设置原则**：
    1.  **硬件故障中断**属于最高级，其次是**软件中断**。
    2.  **非屏蔽中断**优于**可屏蔽中断**。
    3.  **DMA请求**优于**I/O设备传送的中断请求**。
    4.  **高速设备**优于**低速设备**。
    5.  **输入设备**优于**输出设备**。
    6.  **实时设备**优于**普通设备**。
*   **中断处理优先级与屏蔽字** #2011年
    *   **中断响应优先级**：多个中断同时到达时的处理顺序，通常是**硬件特性，固定**的。
    *   **中断处理优先级**：中断嵌套时的抢占关系，**软件可配置，通过中断屏蔽字实现**。
    *   **中断屏蔽字**：控制中断屏蔽状态的寄存器，`Mi = 1` 表示屏蔽该级中断，`Mi = 0` 表示允许。
    *   **屏蔽原则**：当某个中断处理程序执行时，必须**屏蔽自身及所有处理优先级低于自身的中断**。而处理优先级高于自身的中断应保持允许状态，以实现中断嵌套。

#### 3) 处理过程
#2010年 #2012年
当CPU检测到异常或中断发生时，会启动一个特殊的处理过程：
1.  **中断响应 (由CPU硬件自动完成)** (对应中断隐指令) #2012年
    *   **保护断点 (PC)**：CPU硬件自动将当前程序计数器(`PC`)的值保存到特定位置（如堆栈或特定寄存器），然后跳转到中断服务程序入口地址。**断点保存由硬件自动完成，不需要在中断服务程序中显式执行。**
    *   **关中断**：CPU自动将中断允许标志位(`IF`)清零，禁止响应新的可屏蔽中断。这是硬件保护机制，防止中断嵌套导致的系统状态混乱，确保当前中断处理的原子性。
    *   **形成中断服务程序入口地址并送 PC**：CPU硬件通过中断向量表机制，根据中断类型号自动计算并获取对应中断服务程序的入口地址，将其加载到程序计数器(`PC`)中，实现程序控制流的跳转。
>[!danger] **中断隐指令不保存通用寄存器** #2012年
>*   中断隐指令仅保护程序计数器(`PC`)，即断点地址，**不涉及其他通用寄存器的保存操作**。通用寄存器(`EAX`, `EBX`等)的现场保护工作由中断服务程序的软件代码负责完成。
2.  **保存现场 (由中断服务程序软件完成)**： #2010年
    *   中断服务程序首先必须保护被中断程序的执行现场，包括通用寄存器、状态寄存器、索引寄存器等CPU状态信息。现场保护通过将寄存器内容压入堆栈或保存到指定内存区域实现。
3.  **中断事件处理**：
    *   执行具体的中断服务逻辑，如I/O数据传输、异常处理、定时器服务等。这是中断服务程序的核心功能部分。
4.  **恢复现场 (由中断服务程序软件完成)**：
    *   中断事件处理完成后，必须完整恢复被中断程序的执行环境，将之前保存的寄存器值重新装入对应寄存器，确保被中断程序能够正确继续执行。
5.  **开中断** (对于之前关闭的中断)：
    *   在即将返回被中断程序之前开启中断，恢复系统对外部中断的响应能力。这个操作的时机很关键，必须在现场完全恢复后进行。
6.  **中断返回 (由中断服务程序软件+硬件配合)**：
    *   执行中断返回指令(如 `IRET`)，从堆栈中取出断点地址并装入 `PC`，使CPU返回到被中断程序的断点处继续执行。
>[!tip] **单级中断服务程序执行顺序** #2010年
>*   对于单级中断系统，中断服务程序执行顺序为：
> *   **Ⅰ 保护现场 → Ⅴ 中断事件处理 → Ⅵ 恢复现场 → Ⅱ 开中断 → Ⅶ 中断返回**
>*   **关中断 (Ⅲ)** 和 **保护断点 (Ⅳ)** 操作由**硬件在中断响应时自动完成**，不需要在中断服务程序中显式执行。
>*   **单级中断系统特殊性**：服务程序执行期间保持中断关闭状态，不需要在服务程序内部进行开关中断操作来控制嵌套。

---
## 05-6 指令流水线
**指令流水线 (Instruction Pipeline)** 是一种**并行处理技术**。它将一条指令的执行过程分解成多个独立的、顺序的阶段（或子过程），并让多条指令在这些阶段中**重叠**执行，从而提高CPU单位时间内执行的指令数量（即**吞吐率**）。

### 1. 指令流水线的基本概念
*   **核心思想**：类似工厂的"生产线"。每条指令就像一个产品，经过不同的"工位"（流水线阶段）。当一个产品完成一个工位的工作后，就进入下一个工位，而前一个工位则可以立即开始处理下一个产品。
*   **理想流水线阶段**：
    1.  **IF (Instruction Fetch)**：取指令
    2.  **ID (Instruction Decode)**：指令译码 / 读寄存器
    3.  **EX (Execute)**：执行 / 计算操作数地址
    4.  **MEM (Memory Access)**：访存 (数据访问)
    5.  **WB (Write Back)**：写回 (将结果写回寄存器)
*   **流水线寄存器 (Pipeline Registers)**：在每个阶段之间设置的寄存器，用于保存前一阶段的结果，作为后一阶段的输入。它们将流水线的各个阶段隔离开来，实现数据隔离。

### 2. 指令流水线的基本实现
#2011年 #2018年
*   **流水线段的划分**：为方便流水线设计，将每个阶段的耗时取成一样，以**所有阶段中最长的耗时为准**。
    *   例如：各部件实际耗时 `IF: 100ns, ID: 80ns, EX: 70ns, M: 50ns, WB: 50ns`。
    *   则机器周期（或时钟周期）应设置为 `100ns`。
    *   **CPU时钟周期** = $\max(\text{功能部件执行时间}) + \text{流水段寄存器延时}$。 #2018年
*   **缓冲寄存器/锁存器 (Pipeline Registers/Latches)**：
    *   流水线每一个功能段部件后面都要有一个缓冲寄存器，其作用是**保存本流水段的执行结果**，并提供给下一流水段使用。
    *   它们将流水线的各个阶段隔离开来，确保数据的正确传递。

#### (1) 与传统执行方式的对比 (以3阶段为例)
假设一条指令的执行分为3个阶段：**取指 (IF)**、**分析 (ID)**、**执行 (EX)**，每个阶段耗时 `Δt`。
*   **1. 顺序执行方式 (串行执行)**：
    *   **特点**：传统冯·诺伊曼机采用。一条指令完全执行完（`3Δt`）后，下一条指令才能开始。
    *   **总耗时**：`T = n × 3Δt = 3nΔt` (n条指令)。
    *   **优缺点**：
        *   优点：控制简单，硬件代价小。
        *   缺点：执行速度慢，功能部件利用率低（同一时刻只有一个功能部件在工作）。

    ```
    指令1: [IF | ID | EX]
    指令2:             [IF | ID | EX]
    指令3:                         [IF | ID | EX]
    时间轴 ->
    ```

*   **2. 一次重叠执行方式**：
    *   **特点**：在指令1的分析阶段，指令2的取指阶段可以开始。
    *   **总耗时**：`T = 3Δt + (n-1) × 2Δt = (1+2n)Δt` (n条指令)。
    *   **优缺点**：
        *   优点：执行时间缩短，部件利用率提高。
        *   缺点：控制过程比顺序执行复杂，硬件开销增大。

    ```
    指令1: [IF | ID | EX]
    指令2:      [IF | ID | EX]
    指令3:             [IF | ID | EX]
    时间轴 ->
    ```

*   **3. 二次重叠执行方式 (理想流水线)**：
    *   **特点**：每个阶段都可以在上一个阶段完成后，立即开始处理下一条指令。在正常情况下，处理机中同时有3条指令在不同阶段执行。
    *   **总耗时**：`T = kΔt + (n-1) × Δt = (k + n - 1)Δt` (n条指令，k个阶段，此处k=3)。
        *   `T = 3Δt + (n-1) × Δt = (2+n)Δt`。
    *   **优缺点**：
        *   优点：执行时间大幅缩短（比顺序执行缩短近2/3），是一种理想的指令执行方式。
        *   缺点：控制最复杂，硬件开销大。

    ```
    指令1: [IF | ID | EX]
    指令2:      [IF | ID | EX]
    指令3:           [IF | ID | EX]
    时间轴 ->
    ```

> [!TIP] 阶段划分
> 考研中，指令执行过程常划分为5个阶段，这是比较常见的做法。

#### (2) 流水线的表示方法

*   **指令执行过程图**：以指令为行，阶段为列，通过箭头表示指令执行顺序。主要用于分析指令执行过程以及影响流水线的因素（冒险）。
*   **时空图 (Space-Time Diagram)**：以时间为横轴，空间（流水线各阶段/硬件资源）为纵轴。主要用于分析流水线的性能（吞吐率、加速比、效率）。

#### (3) 有利于指令流水线实现的指令系统特点
#2011年
>[!key] **有利于实现指令流水线的特点**
>*   **指令格式规整且长度一致**：
> *   **取指优化**：固定长度指令使 PC 更新规律化，简化指令预取逻辑。
> *   **译码简化**：统一格式减少译码器复杂度，各指令译码时间趋于一致，有助于流水段时间均衡。
*   **指令和数据按边界对齐存放**：
    *   **访存优化**：边界对齐避免跨 Cache 行或内存边界的访问，减少访存延迟。
    *   **时序可预测**：固定的访存周期有利于流水线时序设计，减少流水线停顿。
*   **只有 Load/Store 指令才能对操作数进行存储访问 (Load/Store 架构)**：
    *   **访存时机明确**：只有特定指令访问存储器，便于数据冲突检测和处理。
    *   **功能单元分离**：运算指令与访存指令分离，简化执行单元设计。
    *   **依赖关系清晰**：数据依赖关系易于识别，有利于冲突预测和调度优化。
>[!info] **RISC架构的流水线适应性**
>*   上述三个特征均为 **RISC (精简指令集计算机)** 架构的典型特点。RISC 的设计理念本身就是为了简化硬件实现并提高流水线效率。这些特征协同作用，从指令获取、译码、执行到访存的各个流水段都提供了优化支持。

#### (4) 指令流水线数据通路的组成 #2017年
>[!danger] **控制部件不属于数据通路**
>*   处理器在功能上划分为**数据通路 (Datapath)** 和**控制器 (Controller)** 两个独立部分。
>*   **数据通路**专门负责数据的存储、传输和运算处理。
>*   **控制部件**负责指令解码和控制信号的生成与分发，它通过控制信号来驱动数据通路的操作，但**其本身不属于数据通路的组成部分**。这种分离设计遵循了硬件系统中数据流与控制流分离的基本原则。
>*   **数据通路包含**：
> *   `ALU` (算术逻辑运算部件)：核心执行单元。
> *   `通用寄存器组`：提供数据存储功能。
> *   `取指部件`：负责指令获取。
> *   `多路选择器`、`三态门`、`内部总线`等。
*   数据通路由**组合逻辑电路** (如 ALU、多路选择器) 和**时序逻辑电路** (如流水线寄存器、程序计数器) 组合而成，实现数据的同步传输和处理。

### 3. 流水线的冒险与处理 (Pipeline Hazards)
流水线虽然能提高性能，但并非总能理想运行。当下一条指令的执行需要等待上一条指令的某个结果时，就会发生"冒险" (Hazard)，导致流水线停顿，降低效率。
>[!tip] **判断流水线阻塞的通用技巧** #2010年 #2023年
>*   **冲突识别**：明确区分冒险的原因与解决方案。
>*   **时序分析**：理解流水线各阶段的数据依赖和控制流向。
>*   **性能影响**：判断技术对流水线效率的作用（减少停顿或避免阻塞）。
>*   **硬件实现**：掌握解决路径的具体实现方式（如旁路、阻塞）。

#### (1) 结构冒险 (Structural Hazards) 
#2010年
*   **原因**：多个指令在同一时钟周期内，尝试使用**同一个硬件资源**（如，读写同一个内存端口、使用同一个ALU）。
*   **导致后果**：**引起指令流水线阻塞**。
*   **处理**：
    *   **增加硬件资源**：例如增加独立的指令存储器和数据存储器（哈佛结构），或者增加ALU数量。
    *   **插入气泡 (Stall)**：让冲突的指令等待一个或多个时钟周期，直到资源可用。

#### (2) 数据冒险 (Data Hazards) 
#2010年 #2019年 #2023年
*   **原因**：在一个程序中，存在必须等**前一条指令执行完才能执行后一条指令**的情况（因为后一条指令需要前一条指令的执行结果作为操作数）。
*   **导致后果**：**引起指令流水线阻塞**。
*   **冲突类型**：
    *   **RAW (Read After Write)**：**写后读**。后续指令读取之前，前一条指令必须先写。
        *   `I1: ADD R1, R2, R3` (R1 = R2 + R3)
        *   `I2: SUB R4, R1, R5` (R4 = R1 - R5)
        *   `I2` 需要 `I1` 产生的 `R1` 的值。
    *   **Load-Use 冒险 (Load-Use Hazard)**： #2019年 #2023年
        *   **概念定义**：紧跟 `Load` 指令，后续指令立即使用其从内存加载的数据。
        *   **特点**：`Load` 指令的数据在**访存 (M)** 阶段结束时才从内存中获得并写入寄存器，而紧随其后的指令可能在**执行 (EX)** 阶段就需要该数据。这通常是最严重的数据冒险类型，即使有数据旁路也往往需要**至少阻塞一个周期**。
    *   **WAR (Write After Read)**：**读后写**。后续指令写之前，前一条指令必须先读。
        *   `I1: ADD R2, R4, R5` (R2 = R4 + R5)
        *   `I2: MUL R2, R1, R3` (R2 = R1 * R3)
        *   `I2` 写 `R2`，但 `I1` 已经读了 `R2`。
    *   **WAW (Write After Write)**：**写后写**。后续指令写之前，前一条指令必须先写。
        *   `I1: MUL R1, R2, R3` (R1 = R2 * R3)
        *   `I2: SUB R1, R4, R5` (R1 = R4 - R5)
        *   两条指令都写 `R1`。

>[!TIP] **注意！**
>在采用"**按序发射，按序完成**"的流水线中，通常**只可能出现RAW相关**。WAR和WAW冲突更多出现在乱序执行的流水线中。

*   **解决办法**：
    1.  **暂停相关指令 (Stall / 插入NOP)**：
        *   **硬件阻塞 (Stall)**：当检测到数据相关时，硬件会自动暂停后续指令的执行，插入**气泡**，直到数据可用。
        *   **软件插入"NOP" (No Operation)**：在编译时，编译器检测到相关，手动在相关指令之间插入"空操作"指令，延迟后续指令的执行。
    2.  **数据旁路技术 (Data Forwarding / Bypassing)**： #2010年
        *   **概念定义**：当存在 RAW（Read After Write）数据相关时，旁路技术通过硬件机制将前一条指令在**执行 (EX)** 阶段产生的结果直接转发给需要它的后续指令的输入端，**绕过正常的写回和读取过程，避免等待**。
        *   **特点**：这是最常用的解决RAW冒险的方法，**不会引起指令流水线阻塞**。
    3.  **编译优化 (Compiler Scheduling)**：
        *   编译器通过**调整指令顺序**来避免或减少数据相关。例如，将不相关的指令插入到有相关指令之间，以填补潜在的停顿。
>[!key] **数据冒险识别技巧** #2019年 #2023年
>*   **识别寄存器依赖**：找出读写同一寄存器的指令对。
>*   **判断冒险类型**：区分 RAW、Load-Use 等冒险类型，结合指令类型和执行顺序。
>*   **分析时序关系**：考虑各段流水线的执行时序（如 WB 段写入，ID 段读取；Load 指令数据在 M 段才可用）。
>*   **评估阻塞需求**：Load-Use 冒险通常无法仅靠转发解决，需要阻塞。

#### (3) 控制冒险 (Control Hazards) 
#2010年 #2023年
*   **原因**：当流水线遇到**转移指令**（如条件分支 `Jcc`、无条件跳转 `JMP`、子程序调用 `CALL`、返回 `RET`）和其他改变 `PC` 值的指令时，由于不确定下一条指令的取指地址，会造成流水线断流。
    *   CPU需要等待分支条件判断的结果和目标地址计算完成后，才能确定从哪里取下一条指令。
*   **导致后果**：**引起指令流水线阻塞**。
*   **解决办法**：
    1.  **转移指令分支预测 (Branch Prediction)**：
        *   **简单预测**：总是猜测分支成功（跳转）或总是猜测分支失败（不跳转）。
        *   **动态预测**：根据历史执行情况动态调整预测。预测正确则流水线不中断，预测错误则需要**冲刷 (Flush)** 流水线，清除错误预测带来的指令，并从正确分支重新取指，会带来较大的惩罚。
    2.  **预取转移成功和不成功两个控制流方向上的目标指令**：
        *   同时预取分支的两个可能路径的指令，等到分支结果确定后再选择正确的路径。
    3.  **加快和提前形成条件码**：
        *   尽快计算出分支条件，以便更早地决定分支走向。
    4.  **提高转移方向的猜准率**：通过更复杂的预测算法和历史信息。
    5.  **延迟分支 (Delayed Branch)**：
        *   在分支指令后面插入一些**与分支结果无关**的指令（**延迟槽指令**），这些指令无论分支是否成功都会执行。这样可以填充分支指令带来的延迟。
>[!key] **控制冒险阻塞周期计算** #2023年
>*   在 `5` 段流水线中，分支指令通常在**访存 (M) 段**才能确定是否跳转。
>*   若采用**硬件阻塞方式**处理控制冒险，则紧跟分支指令的后续指令需要**等待分支结果确定**，通常会导致**多个时钟周期**的阻塞（例如，阻塞 `3` 个周期以等待分支指令的 `M` 段完成）。

### 4. 流水线的性能指标
#2013年 #2020年
*   **吞吐率 (Throughput, TP)**：单位时间内流水线所完成的任务数量，或是输出结果的数量。
    *   **计算公式**：$\text{TP} = \frac{\text{n} \cdot \text{f}}{(\text{k}+\text{n}-1)}$ (f是时钟频率，k是流水线段数，n是指令数量)。 #2013年
    *   **理想情况下**：$\text{TP} = \text{f}$ (时钟频率)。当指令数量 `n` 远大于流水线段数 `k` 时，吞吐率趋近于时钟频率。 #2013年
    *   **最大吞吐率**：$\text{TP}_{\text{max}} = \frac{1}{\text{时钟周期}} = \text{f}$ (理想情况下，每隔一个时钟周期完成一条指令)。
*   **加速比 (Speedup, S)**：
    *   `S = 未采用流水线时的执行时间 / 采用流水线时的执行时间`
    *   `S = (n * k * T) / ((k + n - 1) * T)` (n条指令，k个阶段，T是每个阶段时间)
    *   **最大加速比 (Smax)**：`n → ∞` 时，`Smax = k` (加速比接近流水线段数)。
*   **效率 (Efficiency, E)**：
    *   `E = 实际吞吐率 / 理论最大吞吐率 = S / k`
    *   或者 `E = (n * k * T) / (k * (k + n - 1) * T)` (n条指令，k个阶段，T是每个阶段时间)
    *   效率反映了流水线各段被有效利用的程度，通常 `0 < E <= 1`。
*   **CPI (Cycles Per Instruction)**：每条指令平均需要的时钟周期数。 #2020年
    *   **单周期 CPU**：`CPI = 1`。
    *   **多周期 CPU**：`CPI > 1`。
    *   **基本流水线 CPU**：在稳态情况下，理想 `CPI = 1` (每个时钟周期都有一条指令完成执行)。
    *   **超标量流水线 CPU**：理想 `CPI < 1` (每周期可并发执行多条指令， `CPI = 1/n`，n为发射宽度)。

### 5. 高级流水线技术
*   **超标量 (Superscalar)**： #2017年
    *   **概念定义**：CPU中具有**多条并行执行流水线**，在一个时钟周期内，通过多个并行的执行单元（如多个ALU、多个浮点单元），同时**发射 (issue)** 并执行多条不相关的指令。
    *   **特点**：
        *   以**空间换时间**，提高指令级并行度。
        *   能在一个时钟周期内**同时发射多条指令**。
        *   **不能缩短**流水线功能段的**处理时间**。每个功能段的执行延迟由硬件电路的物理特性决定，超标量通过增加执行单元数量实现空间上的并行，而非时间上的加速。
        *   能结合**动态调度技术**（乱序执行）提高指令执行并行性。
    *   **优点**：显著提高指令吞吐量。
    *   **挑战**：需要复杂的硬件来检测指令相关性和调度指令。
*   **超流水技术(Superpipelining)**：在一个时钟周期内再分段。将流水线的每个阶段进一步细分，从而提高时钟频率。
    *   **特点**：
        *   在一个时钟周期内，一个功能部件可以使用多次（例如3次）。
        *   流水线速度是原来速度的倍数（例如3倍）。
        *   不能调整指令的执行顺序。
    *   **优点**：通过提高时钟频率来提高性能。
    *   **挑战**：需要更精密的电路设计，时钟周期更短，更容易受到延迟和冒险的影响。
*   **超长指令字 (Very Long Instruction Word, VLIW)**：由编译器在编译时将多条独立指令打包成一条很长的指令，由硬件并行执行。
    *   **特点**：
        *   指令字很长，包含多个操作码字段。
        *   硬件设计相对简单（因为并行性由编译器负责发现）。
        *   高度依赖**编译程序**的优化能力。
    *   **优点**：可以充分利用硬件资源实现并行。
    *   **挑战**：编译器设计非常复杂，代码移植性差（与特定VLIW架构绑定）。
*   **乱序执行 (Out-of-Order Execution, OOE)**：CPU动态地调整指令的执行顺序，先执行那些操作数已就绪的指令，避免不必要的等待。
*   **分支预测 (Branch Prediction)**：更复杂的硬件预测机制，猜测分支的走向，减少控制冒险带来的停顿。
*   **推测执行 (Speculative Execution)**：在分支预测结果出来之前，根据预测路径预先执行指令，如果预测正确则节省时间，否则丢弃结果。

### 6. 五段式指令流水线：详细阶段与指令执行
五段式指令流水线是一种常见的RISC处理器流水线设计，将指令执行分为以下五个阶段：
1.  **IF (Instruction Fetch)**：**取指**。根据程序计数器(PC)的内容，从**指令Cache**中取出一条指令，并将其送至IF段的锁存器。同时PC更新指向下一条指令。
2.  **ID (Instruction Decode / Register Fetch)**：**译码&取数**。对IF段锁存器中的指令进行译码，识别操作类型、寻址方式和操作数。同时，从**寄存器堆**中取出指令所需的源操作数（若有），并存入ID段锁存器。
3.  **EX (Execute)**：**执行**。根据指令类型，ALU执行算术逻辑运算，或计算内存访问的有效地址。将结果存入EX段锁存器。
4.  **M (Memory Access)**：**访存**。如果指令需要访问内存（LOAD/STORE指令），则通过**数据Cache**进行读/写操作。将从内存中取出的数据或要写入的数据存入M段锁存器。
5.  **WB (Write Back)**：**写回寄存器**。将EX或M段的运算结果或访存结果写回指定的**寄存器**。

> [!NOTE] RISC处理器特性
> 通常，RISC处理器**只有"取数LOAD"和"存数STORE"指令**才能访问主存。运算类指令的操作数都在寄存器之间进行。
> *   减少数据冒险
> *   简化访存MEM阶段
> *   流水线控制更简单

#### (1) 运算类指令的执行过程
*   **示例**：`ADD Rd, Rs` (将 `Rs` 的内容加到 `Rd`，结果存回 `Rd`) 或 `SHL Rd, #N`。
*   **指令功能**：`(Rs) + (Rd) -> Rd`
*   **流水线阶段**：
    *   **IF**：根据PC从指令Cache取指令。
    *   **ID**：取出源操作数 (`Rs`, `Rd`) 的值到ID段锁存器。
    *   **EX**：ALU执行加法/左移运算，将结果存入EX段锁存器。
    *   **M**：**空段** (运算类指令不需要访存数据)。
    *   **WB**：将EX段的运算结果写回指定目的寄存器 (`Rd`)。

#### (2) LOAD指令的执行过程
*   **示例**：`LOAD Rd, 996(Rs)` (将 `(996 + (Rs))` 内存地址处的数据加载到 `Rd` 寄存器)。
*   **指令功能**：`(996 + (Rs)) -> Rd`
*   **流水线阶段**：
    *   **IF**：取指令。
    *   **ID**：取出基址寄存器 `Rs` 的值放入锁存器A，将偏移量 `996` 放入锁存器Imm。
    *   **EX**：ALU计算有效地址 `(Rs) + 996`。
    *   **M**：根据EX段计算出的有效地址，从**数据Cache**中取数，并放入M段锁存器。
    *   **WB**：将从数据Cache中取出的数写回指定目的寄存器 (`Rd`)。

#### (3) STORE指令的执行过程
*   **示例**：`STORE Rs, 996(Rd)` (将 `Rs` 寄存器的内容存入 `(996 + (Rd))` 内存地址)。
*   **指令功能**：`Rs -> (996 + (Rd))`
*   **流水线阶段**：
    *   **IF**：取指令。
    *   **ID**：取出基址寄存器 `Rd` 的值放入锁存器A，将偏移量 `996` 放入锁存器Imm。同时，将要存储的源操作数 `Rs` 的值放入锁存器B。
    *   **EX**：ALU计算有效地址 `(Rd) + 996`。并将锁存器B的内容（即要存储的数据）放入Store段锁存器。
    *   **M**：根据EX段计算出的有效地址，将Store段锁存器中的数据写入**数据Cache**。
    *   **WB**：**空段** (STORE指令的结果是写回内存，不是写回寄存器)。

#### (4) 条件转移指令的执行过程
*   **示例**：`beq Rs, Rt, #偏移量` (若 `(Rs) == (Rt)`，则PC跳转；否则顺序执行)。
*   **指令功能**：`若(Rs)==(Rt),则(PC)+指令字长+(偏移量×指令字长)àPC；否则(PC)+指令字长àPC`
*   **流水线阶段**：
    *   **IF**：取指令。
    *   **ID**：将进行比较的两个数 (`Rs`, `Rt`) 放入锁存器A、B；偏移量放入Imm。
    *   **EX**：ALU执行比较运算 (`Rs == Rt`)，并计算出目标PC值。
    *   **M**：将EX段计算出的目标PC值写回PC寄存器（或更新PC，实现跳转）。
    *   **WB**：**空段** (指令的最终结果是改变PC，不是写回通用寄存器)。
    *   **注**：转移类指令常采用相对寻址。很多教材把写回PC的功能段称为"WrPC段"，其耗时比M段更短，可安排在M段时间内完成。PC通常在IF段结束之后就会自动+1，这里是根据条件修改PC的值。

#### (5) 无条件转移指令的执行过程
*   **示例**：`jmp #偏移量` (PC跳转到新的地址)。
*   **指令功能**：`(PC)+指令字长+(偏移量×指令字长) -> PC`
*   **流水线阶段**：
    *   **IF**：取指令。
    *   **ID**：偏移量放入Imm。
    *   **EX**：ALU计算目标PC值，并将目标PC值写回PC寄存器（或更新PC）。
    *   **M**：**空段**。
    *   **WB**：**空段**。
    *   **注**："WrPC段"耗时比EX段更短，可安排在EX段时间内完成。WrPC段越早完成，就越能避免控制冲突。当然，也有的地方会在WB段时间内才修改PC的值。

## 05-7 多级处理器的基本概念：CPU的"分身术"
随着单核CPU性能提升遇到瓶颈，多核、多处理器成为提高计算机性能的主要方向。

### 1. SISD、SIMD、MIMD 
#2022年
这是对计算机指令流和数据流的经典分类 (Flynn's Taxonomy)：
*   **SISD (Single Instruction Single Data)**：
    *   **单指令流，单数据流**。
    *   传统的单处理器计算机，每次执行一条指令，处理一个数据。
    *   **代表**：单核CPU，非并行处理。
*   **SIMD (Single Instruction Multiple Data)**：
    *   **单指令流，多数据流**。
    *   所有处理器以**同步方式**执行**同一条指令**，但每个处理器处理不同的数据。
    *   **代表**：**向量处理器**、GPU（图形处理器）、多媒体指令扩展（如SSE, AVX），常用于图像处理、科学计算等并行性高、数据密集型任务。
*   **MISD (Multiple Instruction Single Data)**：
    *   **多指令流，单数据流**。
    *   所有处理器对**同一数据流**执行**不同的指令序列**。
    *   实际应用中非常少见，理论上的分类。
*   **MIMD (Multiple Instruction Multiple Data)**：
    *   **多指令流，多数据流**。
    *   每个处理器都有自己的指令流和数据流，可以独立执行不同的程序，处理不同的数据。
    *   **代表**：**多核处理器**、多处理器系统、分布式系统。这是目前最常见的并行计算模型。

### 2. 硬件多线程 (Hardware Multithreading) 
#2022年
*   **核心思想**：为了提高单个处理器核心的利用率，在**一个CPU核心内部**，通过硬件机制支持同时运行**多个线程**。
*   **实现方式**：
    *   **细粒度多线程 (Fine-grained Multithreading)**：在每个时钟周期，处理器在多个线程之间切换，隐藏长延迟操作（如内存访问）带来的停顿。
    *   **粗粒度多线程 (Coarse-grained Multithreading)**：只在发生长延迟停顿时（如Cache Miss），才切换到另一个线程。
    *   **同时多线程 (Simultaneous Multithreading, SMT)**，如Intel的**超线程 (Hyper-Threading)**：允许一个CPU核心的多个功能单元（如ALU、FPU）在**同一个时钟周期**内，同时执行来自**不同线程**的指令。这通过动态共享核心的执行资源（如寄存器、ALU）实现，将一个物理核心模拟成两个或更多的逻辑核心。
*   **优点**：提高了核心的利用率，使得单个核心可以并行执行更多指令。
*   **缺点**：不是真正的物理并行，不同线程仍然共享核心资源，可能会相互竞争。
>[!danger] **硬件多线程的适用范围** #2022年
>*   硬件多线程技术**并非仅限于多核处理器使用**。早期的单核处理器如 Intel 的超线程技术就实现了硬件多线程。
>*   硬件多线程的本质是通过线程级并行来隐藏流水线阻塞和内存访问延迟，因此可以应用于**单核或多核处理器**。

### 3. 多核处理器 (Multi-core Processor) #2022年
*   **核心思想**：将**多个完整的CPU核心**（每个核心都有自己的ALU、CU、寄存器组）集成在**同一块芯片**上。
*   每个核心都可以独立地执行一个线程或一个程序。
*   **优点**：实现了真正的并行处理，显著提高系统的总处理能力。
*   **缺点**：
    *   需要操作系统和应用程序能够支持多线程/多进程编程才能充分利用多核优势。
    *   核心之间的数据共享（如Cache一致性）和通信会带来额外的复杂性。
    *   功耗和散热设计挑战。

### 4. 共享内存多处理器 (Shared-Memory Multiprocessor) #2022年
*   **核心思想**：多个独立的CPU（可以是单核或多核）通过一个共同的**共享内存**来通信和交换数据。
*   所有CPU都可以直接访问相同的物理内存地址空间。
*   **分类**：
    *   **UMA (Uniform Memory Access)**：所有CPU访问内存任何位置的延迟都相同。通常是总线连接。
    *   **NUMA (Non-Uniform Memory Access)**：不同CPU访问不同内存区域的延迟不同，访问本地内存快，访问远程内存慢。
*   **优点**：
    *   编程模型相对简单，通过共享变量进行通信。
    *   数据交换效率高。
*   **缺点**：
    *   内存访问冲突和缓存一致性问题是主要挑战。
    *   随着处理器数量增加，共享内存总线容易成为瓶颈。
*   **代表**：传统的对称多处理器 (Symmetric Multi-Processing, SMP) 系统。
>[!key] **SMP 系统特征** #2022年
>*   **SMP (Symmetric Multi-Processing)** 系统中所有处理器**共享单一的物理地址空间**。
>*   这是 `SMP` 架构的核心特征，所有处理器都能通过相同的物理地址访问共享内存，实现处理器间的数据共享和通信。

---