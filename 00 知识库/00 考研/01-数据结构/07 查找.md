---
科目: "408"
课程名称: 数据结构
tags: []
一轮复习情况: 进行中
二轮复习情况: 未开始
三轮复习情况: 未开始
难度:
考频:
备注:
---

# 07 查找

## 7.1 查找的基本概念
* **查找：** 根据给定的关键字，在查找表中确定是否存在该数据元素。
    * **成功查找：** 找到了！返回它的位置或相关信息。
    * **失败查找：** 没找到！
* **查找表 (Search Table)：** 存放所有数据元素的集合，就是你那一大箱子乐高积木。
* **数据元素：** 就是你要找的那个"东西"，比如乐高积木中的一块砖。
* **关键字 (Key)：** 识别数据元素的唯一标识，比如乐高砖块的"颜色"和"尺寸"。
* **静态查找表：** 查找过程中不改变表中的数据元素（不插入也不删除）。比如你只在现有积木里找。
* **动态查找表：** 查找过程中会伴随插入或删除操作。比如你一边找一边往箱子里加新买的积木，或者把不要的扔掉。
* **平均查找长度**(Average Search Length)：在查找过程中，一次 #查找长度 是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字的比较次数的平均值：$ASL_{success} = \sum_{i=1}^{n} P_i \times C_i$   , $ASL_{success} = \frac{1}{n} \sum_{i=1}^{n} C_i$
* **a. 顺序查找 (Sequential Search)：**
    假设有 `n` 个元素 `(a1, a2, …, an)`，每个元素被查找的概率都是 `1/n`。
    * 查找 `a1` 需要比较 1 次。
    * 查找 `a2` 需要比较 2 次。
    * …
    * 查找 `an` 需要比较 `n` 次。
    $ASL_{success} = \frac{1}{n} (1 + 2 + … + n) = \frac{1}{n} \times \frac{n(n+1)}{2} = \frac{n+1}{2}$
    **结论：** 顺序查找的平均查找长度大约是 `n/2`。当 `n` 很大时，这个值也很大，所以效率低。

* **b. 折半查找 (Binary Search)：**
    折半查找的比较次数与树的高度有关，大约是 `log2(n)`。
    例如，有7个元素的有序数组，查找成功时的ASL：
    * 根节点（中间元素）比较1次。
    * 第二层节点比较2次。
    * 第三层节点比较3次。
    $ASL_{success} \approx log_2 n$
    **结论：** 折半查找的ASL是 `log2(n)` 级别的，比顺序查找高效得多。
    只适用于有序的顺序表

* **c. 散列表查找 (Hash Table Search)：**
    散列表的ASL计算比较复杂，因为它受到散列函数、冲突处理方法和装填因子 `α` 的影响。
    * **理想情况 (无冲突)：** ASL = 1 (直接一次命中)。
    * **拉链法：**
        $ASL_{success} \approx 1 + \frac{\alpha}{2}$ (在均匀散列下)
        $ASL_{failure} \approx \alpha$
    * **线性探测法：**
        $ASL_{success} \approx \frac{1}{2} (1 + \frac{1}{1-\alpha})$
        $ASL_{failure} \approx \frac{1}{2} (1 + \frac{1}{(1-\alpha)^2})$
    **结论：** 散列表的ASL在理想情况下是1，在平均情况下也接近1，所以它是最快的查找方法之一。但当装填因子 `α` 过大时，ASL会急剧增加，性能下降。

**5. 查找失败的平均查找长度 (ASL_failure)：**

除了查找成功，有时我们还需要考虑查找失败时的平均比较次数。
$ASL_{failure} = \sum_{i=1}^{m} P_i \times C_i$ (这里 `m` 是所有可能导致查找失败的路径数)

在考研中，如果题目没有特别说明是成功还是失败，通常默认是**查找成功的平均查找长度**。

---

## 7.2 顺序查找和折半查找
### 1. 顺序查找(Sequential Search)
* **概念：** 就像你找东西，从头开始，一个一个地看，直到找到为止。简单，但效率嘛……你懂的。 #顺序查找
* **C语言实现思路：**
    * **适用于任何线性表（数组、链表）**，无论有序无序。
    * 就是个简单的 `for` 循环或者 `while` 循环。

```c
typedef struct{
    ElemType *elem;     // 指向存储数据元素的数组的指针
    int TableLen;       // 查找表的当前长度（元素个数）
}SSTable; // 顺序查找表（Sequential Search Table）的结构定义

int Search_Seq(SSTable ST, ElemType key){ // 函数：在顺序查找表ST中查找关键字key
    ST.elem[0] = key; // 核心技巧：将要查找的关键字key存入数组的0号位置作为“哨兵”
    for(int i = ST.TableLen; ST.elem[i] != key; --i); // 从数组末尾向前遍历查找
    return i; // 返回找到的元素的下标
}
```

**详细解释：**
1. **`typedef struct { … } SSTable;`**
    * 这是一个结构体定义，用来表示一个"顺序查找表"。
    * `ElemType *elem;`: 这是一个指针，它指向一个存储数据元素的数组。`ElemType` 是一个泛型，表示数据元素的类型，比如可以是 `int`、`char` 或者其他自定义的结构体。
    * `int TableLen;`: 表示这个查找表里当前有多少个数据元素。
2. **`int Search_Seq(SSTable ST, ElemType key)`**
    * 这是一个函数声明，表示我们要实现一个顺序查找的功能。
    * `SSTable ST`: 这是传入的查找表，我们要在这个表里找。
    * `ElemType key`: 这是我们要查找的目标关键字。
    * `int`: 函数的返回值类型，表示找到的元素的下标。
3. **`ST.elem[0] = key;`**
    * **这是这段代码的"灵魂"！** 它使用了**"哨兵"**（Sentinel）技术。
    * **目的：** 为了简化循环条件，避免在循环内部进行两次判断（一次判断是否找到，一次判断是否越界）。
    * **原理：** 将要查找的 `key` 值放到数组的 `0` 号位置。这样，无论 `key` 在数组的哪个位置（包括不存在），循环最终都会在 `ST.elem[i] == key` 时停止。如果 `key` 在 `1` 到 `TableLen` 之间找到了，那 `i` 就是它的下标；如果 `key` 在 `1` 到 `TableLen` 之间没找到，那么循环会一直执行到 `i` 变成 `0`，此时 `ST.elem[0]` 就是 `key`，循环也会停止。
    * **重要假设：** 这种写法**假设你的实际数据元素是从 `ST.elem[1]` 开始存储到 `ST.elem[TableLen]` 的**。也就是说，`ST.elem[0]` 这个位置是专门留出来作为"哨兵"的，不存放实际的有效数据。如果你的数组是从 `0` 开始存放有效数据的，那么这个操作会**覆盖**掉 `ST.elem[0]` 处的原始数据，导致数据丢失！
4. **`for(int i = ST.TableLen; ST.elem[i] != key; --i);`**
    * 这是一个 `for` 循环，但你注意到了吗？它后面直接跟了一个分号 `;`，这意味着**循环体是空的**！所有的操作都在循环的头部完成。
    * `int i = ST.TableLen;`: 循环从表的最后一个元素（下标为 `TableLen`）开始向前查找。
    * `ST.elem[i] != key;`: 这是循环的继续条件。只要当前元素不等于 `key`，就继续循环。
    * `--i;`: 每次循环，下标 `i` 减1，向前移动一个位置。
    * **循环停止时：** 当 `ST.elem[i]` 等于 `key` 时，循环停止。此时的 `i` 就是找到 `key` 的位置。
5. **`return i;`**
    * 返回循环停止时的 `i` 值。
    * **如果 `key` 在 `1` 到 `TableLen` 之间找到了：** `i` 就是 `key` 的下标。
    * **如果 `key` 在 `1` 到 `TableLen` 之间没找到：** 循环会一直执行到 `i` 减到 `0`。此时 `ST.elem[0]` 就是我们之前设置的 `key`，循环停止，函数返回 `0`。
    * **注意：** 返回 `0` 有歧义！它可能表示 `key` 在 `0` 号位置找到了（但我们知道 `0` 号位置是哨兵），也可能表示 `key` 在整个有效数据区（`1` 到 `TableLen`）中没有找到。所以，在使用这种哨兵查找时，通常会约定：如果返回 `0`，就表示查找失败。
* **优点：** 简化了循环条件，避免了每次循环都判断是否越界（`i >= 0`），理论上可以提高一点点效率（减少了条件判断的次数）。
* **缺点：**
    1. **需要占用一个额外的存储空间（`elem[0]`）作为哨兵。**
    2. **会修改原始数据（`elem[0]`），如果 `elem[0]` 本身是有效数据，就会被覆盖。**
    3. **返回 `0` 时有歧义，需要额外约定来判断查找成功还是失败。**

* **时间复杂度：**
    * 最好情况：O(1) (第一个就是你要找的)
    * 最坏情况：O(n) (最后一个是，或者根本不存在)
    * 平均情况：O(n)
* **优点：** 算法简单，对数据结构无特殊要求（有序无序都行）。
* **缺点：** 效率低，数据量一大就慢得让人想睡觉。

### 2. 折半查找(Binary Search)
* **概念：** 这是一个"聪明人"的查找方法！它要求你的数据集合**必须是排好序的**（升序或降序），而且**必须是顺序存储的**（比如数组）。每次查找都从中间开始，如果中间元素不是你要找的，就根据大小关系，把查找范围直接缩小一半！就像你查字典，不会从头翻到尾，而是直接翻到中间，再根据字母大小决定往前翻还是往后翻。#折半查找
* **C语言实现思路：**
    * **注意啦！这里需要用到"数组"的知识！** 如果你对数组的下标访问不熟悉，可能需要回顾一下"第四章 数组与串"中的数组部分。
    * 用 `low` (低位)、`high` (高位)、`mid` (中间位) 三个下标来控制查找范围。
    * 通常用循环实现，也可以用递归。

```c
// 假设SSTable的定义和之前一样，ElemType *elem; int TableLen;
// 并且，非常重要的一点：SSTable中的数据元素必须是【有序】的！
// 比如：L.elem[0], L.elem[1], …, L.elem[TableLen-1] 是从小到大排列的。

int Binary_Search(SSTable L, ElemType key){ // 函数：在有序顺序查找表L中查找关键字key
    int low = 0;         // 查找范围的起始下标（低位指针）
    int high = L.TableLen - 1; // 查找范围的结束下标（高位指针）
    int mid;             // 中间元素的下标

    while (low <= high) { // 只要查找范围有效（低位不大于高位）
        mid = (low + high) / 2; // 计算中间元素的下标

        // 核心逻辑：比较中间元素与目标关键字
        if (L.elem[mid] == key) { // 情况1：中间元素就是我们要找的！
            return mid; // 找到了，返回它的下标
        } else if (L.elem[mid] > key) { // 情况2：中间元素比目标关键字大
            // 说明目标关键字（如果存在的话）一定在中间元素的左边
            high = mid - 1; // 缩小查找范围到左半部分，高位指针移到mid-1
        } else { // L.elem[mid] < key  // 情况3：中间元素比目标关键字小
            // 说明目标关键字（如果存在的话）一定在中间元素的右边
            low = mid + 1; // 缩小查找范围到右半部分，低位指针移到mid+1
        }
    }
    // 循环结束，说明low > high，查找范围已经为空，即没有找到目标关键字
    return -1; // 没找到，返回-1（通常用-1表示查找失败）
}

```

* **时间复杂度：** O(log n) (非常非常高效！)
* **优点：** 查找效率极高，是处理大规模有序数据的首选。
* **缺点：**
    * **要求数据必须有序！** 如果数据无序，你得先排序，那排序本身也需要时间。
    * **只能在顺序存储结构（如数组）上实现。** 如果是链表，你不能直接跳到中间，所以不能用折半查找。
* **考点：** 掌握其原理、实现，以及与顺序查找的对比。

#### 折半查找的ASL (Average Search Length)
**1. 二叉判定树 (Binary Decision Tree)**
在分析折半查找的ASL时，我们通常会引入**二叉判定树**的概念。
* **节点：** 树中的每个节点代表一次比较操作。
* **左子树：** 如果比较结果是 `key < L.elem[mid]`，则进入左子树查找。
* **右子树：** 如果比较结果是 `key > L.elem[mid]`，则进入右子树查找。
* **叶子节点：** 代表查找失败的情况。
* **成功查找：** 对应于树中某个内部节点（即 `L.elem[mid] == key`）。

**2. 查找成功时的ASL (ASL_success)**
假设查找表中有 `n` 个元素，且每个元素被查找的概率相等（都为 `1/n`）。
* **比较次数：** 查找成功时，比较次数等于该元素在二叉判定树中的**层数**（或深度+1）。
    * 根节点（第1层）的元素比较1次。
    * 第2层节点比较2次。
    * 第k层节点比较k次。
* **理想情况 (完全二叉判定树)：**
    当 `n = 2^k - 1` 时（例如 `n=7, k=3`），二叉判定树是一棵满二叉树，也是一棵完全二叉树。此时，所有成功查找的路径长度都比较均衡。
    $ASL_{success} = \frac{1}{n} \sum_{i=1}^{n} C_i$
    对于一个有 `n` 个元素的有序表，其二叉判定树的高度大约是 `log2(n+1)`。
    因此，**折半查找的平均查找长度近似为 $log_2 n$。**
    **更精确的计算（对于查找成功）：**
    对于 `n` 个元素的有序表，其ASL_success的精确公式通常是：
    $ASL_{success} = \frac{1}{n} \sum_{i=1}^{n} (\lfloor log_2 i \rfloor + 1)$
    这个公式比较复杂，在考研中通常不会要求你直接用这个公式计算，而是理解其近似值。

    **一个更常用的近似公式（对于查找成功）：**
    $ASL_{success} \approx log_2(n+1) - 1$

**3. 查找失败时的ASL (ASL_failure)**

查找失败的ASL对应于二叉判定树中所有**叶子节点**的路径长度。
对于 `n` 个元素的有序表，有 `n+1` 个查找失败的可能情况（对应于 `n+1` 个叶子节点）。

$ASL_{failure} \approx log_2(n+1)$

### 3. 分块查找
* **概念：** 它是顺序查找和折半查找的"混血儿"。适用于数据量大，但又不想完全排序的情况。它把数据分成若干块，每块内部可以无序，但块与块之间是"有序"的（比如，第一块的最大值小于第二块的最小值）。然后建立一个**索引表**，索引表里记录了每块的起始地址和最大（或最小）关键字。
    * **查找步骤：**
        1. **在索引表中进行折半查找**（因为索引表是按块有序的），找到目标关键字可能在哪一块。
        2. **在定位到的块内进行顺序查找**（因为块内是无序的）。
* **C语言实现思路：**
    * 需要两个数据结构：一个存储原始数据的**大数组**，一个存储块信息的**索引表（通常也是数组）**。
    * **注意啦！这里需要用到"数组"和"结构体"的知识！**

    ```c
    // 示例：分块查找的结构（简化）
    #define BLOCK_SIZE 10 // 每块大小
    #define BLOCK_NUM 5   // 块的数量

    // 原始数据数组
    int data[BLOCK_SIZE * BLOCK_NUM];

    // 索引表结构
    typedef struct {
        int maxKey; // 该块的最大关键字
        int startIndex; // 该块在data数组中的起始下标
    } IndexBlock;

    IndexBlock indexTable[BLOCK_NUM]; // 索引表数组

    // 查找过程：
    // 1. 在indexTable中折半查找，找到key可能在哪一块
    // 2. 在定位到的块（data[startIndex]到data[startIndex + BLOCK_SIZE - 1]）中顺序查找key
    ```

* **时间复杂度：** O(log (块数) + 块内长度) = O(log(n/m) + m)，其中n是总元素数，m是块长。
    * 当 `m = sqrt(n)` 时，时间复杂度最优，为 O(sqrt(n))。
* **优点：** 结合了顺序查找和折半查找的优点，不需要数据完全有序，效率比顺序查找高。
* **缺点：** 需要额外的索引表空间，维护索引表有开销。
* **考点：** 理解其查找原理，时间复杂度分析。
## 7.3 树形查找
### 1. 二叉排序树(Binary Search Tree/BST)
* **概念：** 简称BST，也叫二叉查找树。它是一种特殊的二叉树，满足以下性质：
    1. 若左子树不空，则左子树上所有节点的值均小于根节点的值。
    2. 若右子树不空，则右子树上所有节点的值均大于根节点的值。
    3. 左右子树也都是二叉排序树。
    4. 没有关键字相同的节点（通常情况下）。
* **C语言实现思路：**
    * 使用**二叉链表**来存储。

```c
    typedef struct BiTNode {
        int data;
        struct BiTNode *lchild, *rchild; // 左右孩子指针
    } BiTNode, *BiTree;

    // 查找操作 (递归实现)
    BiTNode* BST_Search(BiTree T, int key) {
        if (T == NULL || T->data == key) {
            return T; // 树空或找到
        }
        if (key < T->data) {
            return BST_Search(T->lchild, key); // 在左子树查找
        } else {
            return BST_Search(T->rchild, key); // 在右子树查找
        }
    }

    // 插入操作 (递归实现)
    void BST_Insert(BiTree *T, int key) {
        if (*T == NULL) { // 找到插入位置
            *T = (BiTNode*)malloc(sizeof(BiTNode));
            (*T)->data = key;
            (*T)->lchild = (*T)->rchild = NULL;
            return 1;
        } 
        else if (key < (*T)->data) {
            BST_Insert(&(*T)->lchild, key);
        } else if (key > (*T)->data) {
            BST_Insert(&(*T)->rchild, key);
        }
        // 如果key等于(*T)->data，通常不插入（或更新）
    }

    // 删除操作：比较复杂，需要考虑多种情况（叶子节点、只有一个孩子、有两个孩子）
    // 考研通常要求理解其逻辑，手写代码难度较大，但要能分析其过程。

//构造  
void Creat_BST(BSTtree &T,int str[],int n){  
    T=NULL;  
    int i=0;  
    while(i=n){  
        BST_Insert(T,str[i]);  
        i++;  
    }  
}

```

* **时间复杂度**：
    * 最好/平均情况：O(log n) (树是平衡的)
    * 最坏情况：O(n) (树退化成链表，比如插入的元素总是递增或递减)
* **优点：** 动态查找（支持插入删除），平均效率高。
* **缺点：** 最坏情况下效率退化，树可能不平衡。
* **考点：** **BST的定义、查找、插入、删除操作的原理和实现。**
* **平均查找长度**：
![[7.3.1 二叉排序树.pdf#page=21&rect=63,21,841,482|7.3.1 二叉排序树, p.21]]
### 2. 平衡二叉树(AVL)（根据作者名字命名）
* **概念：** 为了解决BST在最坏情况下退化成链表的问题，就有了 #平衡二叉树 。AVL树是最早的平衡二叉树。它要求：**任何一个节点的左子树和右子树的高度差的绝对值不超过1。**
* **C语言实现思路：**
    * 在BST的基础上，每个节点需要额外存储一个**平衡因子 (Balance Factor)**，表示左右子树的高度差（左子树高-右子树高）。
    * 当插入或删除导致不平衡时，需要通过**旋转操作**来恢复平衡。
        * **LL型：** 左孩子的左子树插入导致不平衡，进行右旋。
             * ![[考研学习笔记01-数据结构 07 查找 2025-10-17 2929.png|816x172]]![[考研学习笔记01-数据结构 07 查找 2025-10-17 3052.png]]
        * **RR型：** 右孩子的右子树插入导致不平衡，进行左旋。
            * ![[考研学习笔记01-数据结构 07 查找 2025-10-17 3131.png]]![[考研学习笔记01-数据结构 07 查找 2025-10-17 3151.png]]
        * **LR型：** 左孩子的右子树插入导致不平衡，先左旋再右旋。
            * ![[考研学习笔记01-数据结构 07 查找 2025-10-17 3513.png]]![[考研学习笔记01-数据结构 07 查找 2025-10-17 3547.png]]
        * **RL型：** 右孩子的左子树插入导致不平衡，先右旋再左旋。
            * ![[考研学习笔记01-数据结构 07 查找 2025-10-17 3613.png]]![[考研学习笔记01-数据结构 07 查找 2025-10-17 3633.png]]
* **时间复杂度：** 查找、插入、删除都是 O(log n) (始终保持平衡)。
* **优点：** 始终保持高效的查找、插入、删除性能。
* **缺点：** 维护平衡的开销较大，实现复杂。
* **考点：** **平衡因子的概念、四种旋转操作（LL, RR, LR, RL）的原理和图示。** 通常不要求手写完整的AVL树实现，但要能分析旋转过程。

### 3. 红黑树
* **概念：** 另一种**自平衡** #二叉查找树 。它通过给节点着色（红色或黑色）并遵循一系列规则来保证树的平衡，从而确保查找、插入、删除操作的效率。
* **特点**：
    1. 每个节点非红即黑。
    2. 根节点是黑色的。
    3. 所有叶子节点（NULL节点，空节点）是黑色的。(根叶黑)
    4. 如果一个节点是红色的，则它的两个子节点都是黑色的（不能有两个连续的红色节点）。（不红红）
    5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。（黑路同，#黑高 (不含该节点本身)）
* **时间复杂度：** 查找、插入、删除都是 $O(log_2 n)$。红黑树的高度最多为 $2log_2​(n+1)$，因此红黑树的操作（包括插入和删除）在最坏情况下的时间复杂度为 $O(log_2n)$。
* **优点：** 相比AVL树，红黑树的平衡条件更宽松，因此在插入和删除时，旋转次数通常更少，性能更稳定。在实际应用中（如C++ STL的`map`和`set`，Java的`TreeMap`和`TreeSet`），红黑树更常用。
* **红黑树的插入**：
    * 先查找，确定插入位置（原理同 #二叉排序树）
    * 非根节点优先染成红色，若插入新节点不满足红黑树定义，进行调整。
        * 黑叔 旋转+染色
            * LL型：右单旋，父换爷+染色（父爷染另外一种颜色）
            * RR型：左单旋，父换爷+染色
            * LR型：先左旋后右旋，儿换爷+染色
            * RL型：先右旋再左旋，儿换爷+染色
        * 红叔 染色+变新
            * 叔父爷染色，爷变为新结点

---

## 7.4 B树和B+树
#必考
### 1. B树及其基本操作
*   **概念：** B 树 (B-Tree) 是一种**多路查找树**（或称平衡多叉树），它能保持树的平衡，并且每个节点可以存储多个关键字和多个子树指针。它的主要目的是**优化磁盘 I/O 操作**，特别适合存储在外部存储器（如磁盘）上的大型数据库和文件系统索引。![[考研学习笔记01-数据结构 07 查找 B树示意图.png]]
    *   **关键字**：存储在节点中的数据项，用于比较和查找。
    *   **子树指针**：指向孩子节点的指针。
*   **特点 (m 阶 B 树)**：`m` (阶数) 表示一个节点最多可以有多少个子节点。
    1.  **节点关键字数量范围：**
        *   除根结点外，所有非叶结点（包括叶结点）：`⌈m/2⌉ - 1 ≤ k ≤ m - 1` 个关键字。
        *   根结点：`1 ≤ k ≤ m - 1` 个关键字（除非树为空，根结点为叶结点，此时 `k = 0`）。
    2.  **节点子节点数量范围：**
        *   除根结点外，所有非叶结点：`⌈m/2⌉ ≤ p ≤ m` 个子节点。
        *   根结点：`2 ≤ p ≤ m` 个子节点（除非根结点是叶子结点，此时 `p = 0`）。
    3.  **所有叶子节点都在同一层**：这是 B 树保持平衡的关键性质，确保了所有从根到叶的路径长度相同，因此所有查找操作的效率都是稳定的。
    4.  **节点内部关键字有序排列：**![[考研学习笔记01-数据结构 07 查找 B树关键字.png]]节点内部的关键字是升序排列的。
        *   一个节点内有 `k` 个关键字 `K1, K2, …, Kk`，满足 `K1 < K2 < … < Kk`。
        *   有 `k+1` 个指向子树的指针 `P0, P1, …, Pk`。
        *   指针 `P0` 指向的子树中所有关键字都小于 `K1`。
        *   指针 `Pi` (1 ≤ i ≤ k-1) 指向的子树中所有关键字都大于 `Ki` 且小于 `Ki+1`。
        *   指针 `Pk` 指向的子树中所有关键字都大于 `Kk`。
    5.  **注**：大部分学校算 B 树的**高度不包括叶子结点**（失败结点）。如果高度为 `h`，则根结点层为 1，最底层的非叶结点层为 `h`。

*   **B 树的高度**：对于包含 `n` 个关键字的 `m` 阶 B 树。
    *   **最小高度 `h_min` (节点尽可能满):**
        *   根结点至少有 1 个关键字，2 个孩子。
        *   其他非叶结点至少有 `⌈m/2⌉ - 1` 个关键字，`⌈m/2⌉` 个孩子。
        *   最满的情况是所有节点都有 `m-1` 个关键字和 `m` 个孩子。
        *   叶子结点（存储实际数据或指向实际数据的指针）在第 `h` 层。
        *   在高度为 `h` 时，总结点数最少为 `1 + 2 + 2 * ⌈m/2⌉ + …`
        *   在高度为 `h` 时，关键字数 `n ≥ 1 + (m-1) * (m^(h-1) - 1) / (m-1)` (不太严谨)
        *   **更常见的推导：** 当每个节点都是满的，即有 `m-1` 个关键字和 `m` 个孩子时，`n ≤ m^h - 1`，则 $h \ge \log_m(n+1)$。
        *   **准确推导：** 根节点至少1个关键字。第1层1个结点。第2层至少2个结点。第3层至少$2 \cdot \lceil m/2 \rceil$个结点。第h+1层至少$2 \cdot \lceil m/2 \rceil^{h-1}$个叶结点。
        *   关键字总数 `n` 至少为 `1 + (2-1) + (2*⌈m/2⌉-1) + …`
        *   **最简公式：** $h \ge \log_m (\frac{n+1}{2}) + 1$ (这个是考虑根节点1个关键字，其他节点`m-1`个关键字的情况)。
        *   **考点核心：** 理解高度与关键字数量、阶数之间的对数关系，即查找效率与树的高度成正比。
    *   **最大高度 `h_max` (节点尽可能稀疏):**
        *   根节点只有 1 个关键字，2 个分叉。
        *   其他结点只有 `⌈m/2⌉ - 1` 个关键字，`⌈m/2⌉` 个分叉。
        *   第 1 层：1 个节点
        *   第 2 层：2 个节点
        *   第 3 层：`2 * ⌈m/2⌉` 个节点
        *   第 `h` 层：`2 * ⌈m/2⌉^(h-2)` 个节点
        *   第 `h+1` 层（叶子节点层）共有 `2 * ⌈m/2⌉^(h-1)` 个叶子节点。
        *   因为 `n` 个关键字的 B 树必有 `n+1` 个叶子结点（失败结点），所以 `n+1 >= 2 * ⌈m/2⌉^(h-1)`。
        *   即 `h-1 <= log_⌈m/2⌉((n+1)/2)`，则 $h \le \log_{⌈m/2⌉}(\frac{n+1}{2}) + 1$。
        *   **注：** 这里 `⌈m/2⌉` 通常写作 `k`，即每个非根节点最少有 `k-1` 个关键字和 `k` 个孩子。则 $h \le \log_k(\frac{n+1}{2}) + 1$。
        ![[考研学习笔记01-数据结构 07 查找 B树高度和节点数的关系.png]]
*   **C 语言实现思路：**
    *   节点结构会比较复杂，通常用结构体 `struct BTreeNode` 来表示。
        *   `int *keys;` (关键字数组)
        *   `struct BTreeNode **children;` (子节点指针数组)
        *   `int numKeys;` (当前关键字数量)
        *   `bool isLeaf;` (是否是叶子节点)
    *   **操作 (查找、插入、删除) 涉及节点的分裂和合并，这是其核心和难点。**
        *   **查找:** 类似二叉搜索树，从根开始，根据关键字在节点内有序查找，决定进入哪个子树。
        *   **插入:** 找到叶子结点插入。如果叶子结点满载 (m-1 个关键字)，则**分裂**成两个结点，中间关键字提升到父结点。如果父结点也满，继续分裂并提升，可能导致树的高度增加。
        *   **删除:**
            *   **若删除叶子结点中的关键字：** 直接删除。如果关键字数量少于 `⌈m/2⌉ - 1` (下溢)，则尝试向兄弟结点**借关键字**（若兄弟结点富余），或与兄弟结点**合并**，并调整父结点中的关键字。
            *   **若删除非叶子结点中的关键字：** 用其**后继关键字**（在右子树的最左叶结点中）或**前驱关键字**（在左子树的最右叶结点中）替换，然后删除该叶子结点中的后继/前驱关键字，转化为叶子结点的删除问题。
#### I. B-树的插入操作 (Insertion)
插入操作总是发生在**叶子节点**。
1.  **查找插入位置：**
    *   从根节点开始，通过关键字的比较，沿着合适的子树指针向下查找，直到找到应该插入关键字的**叶子节点**。
2.  **插入关键字：**
    *   将新的关键字插入到找到的叶子节点中，并保持节点内部关键字的有序性。
3.  **处理节点满载 (上溢 - Overflow)：**
    *   **情况 3.1：** 如果插入后该叶子节点的关键字数量 `k` **小于 `M-1`** (即未满载)，则插入完成，操作结束。
    *   **情况 3.2：** 如果插入后该叶子节点的关键字数量 **等于 `M`** (即发生上溢，因为节点最多只能有 `M-1` 个关键字)：
        *   **分裂 (Split) 操作：**
            1.  将该节点（包含 `M` 个关键字和 `M+1` 个子指针，如果它是内部节点）从中间位置劈开。
            2.  取出**中间的关键字**（通常是第 `⌈M/2⌉` 个关键字）。
            3.  将该关键字**提升 (Promote)** 到它的**父节点**中。
            4.  将原节点分裂为两个新节点：
                *   **左子节点：** 包含中间关键字左边的所有关键字和对应的子树。
                *   **右子节点：** 包含中间关键字右边的所有关键字和对应的子树。
            5.  提升的关键字在父节点中起到分隔左右两个新节点的作用。
    *   **情况 3.3：** **递归分裂 (Propagating Split)：**
        *   如果父节点在接收到提升的关键字后，也发生了上溢（关键字数量达到 `M`），则父节点也需要进行分裂，将其中间的关键字提升到其父节点，这个过程会**向上递归**。
        *   **根节点分裂：** 如果分裂一直传播到根节点，并且根节点也发生上溢，那么根节点也会分裂，并提升中间关键字形成一个新的根节点。此时，**B-树的高度会增加 1**。

**插入示例图 (M=3 阶 B 树)：**
*   **初始节点** `[10 20]` (已满，`M-1=2`)
*   **插入 15**
    1.  `[10 15 20]` (临时 3 个关键字，上溢)
    2.  **分裂：** 中间关键字 `15` 提升到父节点。
    3.  原节点分裂成 `[10]` 和 `[20]`。
    4.  父节点接收 `15`，更新其结构。

#### II. B-树的删除操作 (Deletion)
删除操作通常比插入复杂，因为它可能导致**下溢 (Underflow)**，需要进行借关键字或合并操作。
1.  **查找关键字：**
    *   从根节点开始查找要删除的关键字 `K`。
2.  **处理删除情况：**
    *   **情况 2.1：要删除的关键字 `K` 位于叶子节点中。**
        1.  **直接删除：** 从该叶子节点中删除 `K`。
        2.  **检查下溢：** 删除后，如果该叶子节点的关键字数量 `k` **仍然满足 `k ≥ ⌈M/2⌉ - 1`** (即没有下溢)，则删除完成，操作结束。
        3.  **处理下溢 (当 `k < ⌈M/2⌉ - 1`)：**
            *   **选项 A：向兄弟结点借关键字 (Rotation / Redistribution)**
                *   检查该叶子节点的**相邻兄弟结点**（左兄弟或右兄弟）。
                *   如果某个兄弟结点拥有**多余的关键字** (即其关键字数量 `k_sibling > ⌈M/2⌉ - 1`)，则可以向其借关键字。
                *   **具体步骤：**
                    1.  将父节点中分隔该叶子节点与兄弟结点的关键字（我们称之为分隔关键字）**下移**到当前下溢的叶子节点中。
                    2.  将兄弟结点中**最接近分隔关键字**的那个关键字（如果借左兄弟，就是其最大关键字；如果借右兄弟，就是其最小关键字）**上移**到父节点中，取代原分隔关键字的位置。
                    3.  相应地调整子树指针（如果涉及内部节点）。
                *   **示例：** 你刚才的问题就是这个情况！删除 78，结点 `[78]` 下溢。其父结点 `[55 65]`，左兄弟 `[60 62]` 有多余关键字。
                    *   `65` 下移到 `[ ]`，使其变为 `[65]`。
                    *   `62` (左兄弟最大) 上移到父结点，替换 `65`，父结点变为 `[55 62]`。
                    *   左兄弟 `[60 62]` 变为 `[60]`。
                *   操作完成，树恢复平衡。
            *   **选项 B：与兄弟结点合并 (Merging)**
                *   如果所有相邻兄弟结点都没有多余的关键字（即它们都只有 `⌈M/2⌉ - 1` 个关键字，无法借出），则需要将当前下溢的叶子节点与一个相邻的兄弟结点**合并**。
                *   **具体步骤：**
                    1.  从父节点中移除分隔这两个兄弟结点的关键字。
                    2.  将该分隔关键字与两个兄弟节点中的所有关键字和子树**合并**成一个新的节点。
                    3.  **递归合并：** 父节点在失去一个关键字和一根子树指针后，可能也会发生下溢。如果发生，则需要对父节点递归执行上述“借关键字”或“合并”操作，这个过程会**向上递归**。
                    4.  **根节点下溢：** 如果合并一直传播到根节点，并且根节点只剩下一个关键字并与子节点合并，或者根节点只有一个孩子，那么根节点被删除，其唯一的孩子成为新的根节点，此时 **B-树的高度会减少 1**。
    *   **情况 2.2：要删除的关键字 `K` 位于非叶子节点中。**
        1.  `K` 不能直接删除，因为它作为分隔符组织子树。
        2.  **查找替换关键字：** 找到 `K` 在 B-树中的**有序前驱**（`K` 左子树中最大的关键字）或**有序后继**（`K` 右子树中最小的关键字）。这两个替换关键字总是位于**叶子节点**中。
        3.  **替换：** 用这个找到的前驱/后继关键字替换非叶子节点中的 `K`。
        4.  **删除叶子节点中的替换关键字：** 现在问题转化为从叶子节点中删除一个关键字，这又回到了 **情况 2.1** 的处理流程，可能需要进行借关键字或合并操作。
**删除示例图 (M=3 阶 B 树)：**
*   **初始父节点** `[100]`，孩子 `[50 70]` (左), `[120 150]` (右)
*   **删除 70** (从叶子节点删除)
    1.  `[50 70]` 变为 `[50]` (下溢，因为 `⌈3/2⌉-1 = 1`)
    2.  检查右兄弟 `[120 150]`，它有多余关键字。
    3.  **借关键字：**
        *   父节点的 `100` 下移到 `[50]`，变为 `[50 100]`。
        *   右兄弟的 `120` 上移到父节点，替换 `100`，父节点变为 `[120]`。
        *   右兄弟 `[120 150]` 变为 `[150]`。
    4.  操作完成，树恢复平衡。

*   **时间复杂度：** 查找、插入、删除操作的平均和最坏时间复杂度都是 $O(log_m n)$。 (m 是阶数，通常很大，所以树的高度很低，磁盘 I/O 次数少)。
*   **优点：**
    *   **减少磁盘 I/O 次数：** 这是 B 树最主要的优点。由于每个节点可以存储大量关键字和指针，使得 B 树的高度很低，访问数据时需要读取的磁盘块数量大大减少。
    *   **保持树的平衡：** 严格的规则确保了树的平衡性，所有查找路径长度一致，查询性能稳定。
    *   **支持范围查询：** 虽然不如 B+ 树，但在一定程度上也能支持。
*   **缺点：** 实现复杂，内存空间利用率可能不如二叉树。
*   **考点：** **B 树的定义、阶数 `m` 的含义、节点结构、基本性质、插入和删除操作的原理（特别是节点分裂和合并的详细过程和图示）。** 


### 2. B+树的基本概念
*   **概念：** B+ 树是 B 树的一种变体，通常在数据库索引中比 B 树更常用。它在 B 树的基础上做了关键优化，进一步提升了范围查询的效率和查询的稳定性。
*   **特点 (与 B 树的主要区别):**
    1.  **所有关键字都出现在叶子节点中：**
        *   非叶子节点（也称索引节点）只存储用于导航的关键字和子节点指针，不存储实际数据记录。
        *   实际的数据记录（或指向数据记录的指针）只存储在叶子节点中。
        *   叶子节点包含所有关键字。
    2.  **所有叶子节点构成一个有序链表：**
        *   叶子节点之间通过指针连接，形成一个从左到右的单向或双向链表。
        *   这极大地便利了范围查询。
    3.  **非叶子节点只存储关键字和子节点指针，不存储实际数据：**
        *   这使得一个非叶子节点（一个磁盘块）可以存储更多的关键字和指针，从而进一步降低了树的高度。
        *   树的高度更低，意味着查询所需的磁盘 I/O 次数更少。
*   **优点：**
    *   **更适合范围查询：** 由于所有叶子节点构成了有序链表，范围查询（例如 `WHERE key BETWEEN A AND B`）只需找到起始叶子节点，然后沿着链表遍历即可，效率极高。
    *   **查询效率更稳定：** 无论查询成功与否，所有查询都必须从根节点走到叶子节点，因此查询路径长度固定，效率稳定。
    *   **磁盘 I/O 更少：** 非叶子节点不存储数据，可以存储更多的索引信息，减少树的高度。这在数据库索引中至关重要。
    *   **支持全表扫描：** 通过遍历叶子节点链表即可实现。
*   **缺点：** 插入和删除操作也相对复杂，需要维护链表结构。
*   **考点：** **B+ 树与 B 树的核心区别（所有关键字在叶子节点、叶子节点形成链表、非叶子节点只作索引），以及 B+ 树在数据库索引中的独特优势（范围查询、稳定查询效率、更低的树高）。**
---

## 7.5 散列（Hash）表
### 1. #散列Hash表 表 的基本概念
* **散列 (Hashing)：** 将关键字通过 #散列函数 映射到存储地址的过程。
* **散列表 (Hash Table)：** 根据关键字直接访问数据存储位置的数据结构。
* **散列函数 (Hash Function)：** 将关键字映射为存储地址的函数。#散列函数
* **冲突 (Collision)：** 不同的关键字经过散列函数计算后，得到了相同的存储地址。减少冲突：构造更合适的函数。
    * #拉链法
    * #开放定址法

### 2. 散列函数的构造方法
* **除留余数法 ($\Delta$)：** `H(key) = key % p` (p通常取小于表长的最大素数)
* **直接定址法：** `H(key) = a * key + b` (简单，但要求关键字分布均匀且范围小)
* **数字分析法：** 分析关键字的分布，选取分布均匀的位作为散列地址。
* **平方取中法：** 将关键字平方后取中间几位作为散列地址。

| 方法    | 散列函数                 | 适用场景                    |     |
| ----- | -------------------- | ----------------------- | --- |
| 除留余数法 | H(key) = key % p     | 较为通用，只要关键字是整数即可         |     |
| 直接定址法 | H(key) = a × key + b | 关键字分布基本连续               |     |
| 数字分析法 | 选取数码分布较均匀的若干位        | 关键字集合已知，且关键字的某几个数码位分布均匀 |     |
| 平方取中法 | 取关键字平方值的中间几位         | 关键字的每位取值都不够均匀           |     |
设计散列函数的原则：
1. 定义域必须涵盖所有可能出现的关键字。
2. 值域不能超出散列表的地址范围。
3. 尽可能减少冲突。散列函数计算出来的地址应尽可能均匀分布在整个地址空间。
4. 散列函数应尽量简单，能够快速计算出任意关键字的地址。

### 3. 处理冲突的方法
冲突是不可避免的，所以如何优雅地解决冲突是散列表的关键！
* #开放定址法 (Open Addressing)：当发生冲突时，为冲突的元素寻找下一个空的地址。
* $$H_i=(H(key)+d_i)\%m$$
    * **线性探测法 (Linear Probing)：** 冲突了就往后一个一个找空位，直到找到空位或回到原点。
        * 其中 `d_i = 0, 1, 2, …, m-1`
        * **缺点：** 容易形成"堆积"现象，导致后续查找效率降低。
    * **二次探测法 (Quadratic Probing)：** 冲突了就按 `1^2, -1^2, 2^2, -2^2, …` 的步长找空位。
        * `H_i(key) = (H(key) + d_i) % m`，其中 `d_i = 0, 1^2, -1^2, 2^2, -2^2, …`
        * **优点：** 缓解了线性探测的堆积问题。
    * **双重散列 (Double Hashing)：** 用第二个散列函数来决定探测的步长。
        * $$H_i(key) = (H_1(key) + i * H_2(key)) \% m$$
        * **优点：** 避免了堆积，探测序列更随机。
    * **伪随机序列法**:
        人为设计一个伪随机序列
只能进行逻辑删除，添加删除标记。查找效率低下。

* #拉链法 (Chaining / 链地址法) (常用！)：
    * **概念：** 将所有冲突的元素组织成一个**链表**，挂在散列表的对应位置上。散列表的每个"桶"都是一个链表的头指针。
查找失败时只查找到空指针不计入 #查找长度 （只计算关键字的次数）

```c
  // 示例：拉链法哈希表结构（简化）
 #define TABLE_SIZE 10 // 散列表大小

 // 链表节点结构
  typedef struct HashNode {
     int key;
      // 其他数据…
     struct HashNode *next;
 } HashNode;

 // 散列表：一个指针数组，每个指针指向一个链表的头
 HashNode *hashTable[TABLE_SIZE];

 // 散列函数示例
  int hash(int key) {
     return key % TABLE_SIZE;
 }

 // 插入操作
  void insertHash(int key) {
     int index = hash(key);
     HashNode *newNode = (HashNode *)malloc(sizeof(HashNode));
     newNode->key = key;
    newNode->next = hashTable[index]; // 头插法插入链表
    hashTable[index] = newNode;
 }

 // 查找操作
HashNode* searchHash(int key) {
     int index = hash(key);
      HashNode *current = hashTable[index]; // 遍历对应链表
      while (current != NULL) {
              if (current->key == key) {
             return current; // 找到
       }
         current = current->next;
      }
      return NULL; // 没找到
 }
```

* **考点：** **两种主要冲突处理方法（开放定址法和拉链法）的原理、优缺点、以及各自的典型实现（线性探测、拉链法）。**

### 4. 散列查找及性能分析的应用
* **装填因子 (Load Factor)：** `α = n / m` (n是表中元素个数，m是散列表长度)。它反映了散列表的"拥挤"程度。装填因子越大，冲突的可能性越大，查找效率越低。
* **平均查找长度 (ASL)：** 衡量查找效率的指标。
* **考点：** **理解装填因子对散列表性能的影响，能够分析不同冲突处理方法下的平均查找长度。**

---
