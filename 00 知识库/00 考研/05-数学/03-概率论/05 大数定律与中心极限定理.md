---
科目: 
课程名称: 
tags: []
一轮复习情况: 进行中
二轮复习情况: 未开始
三轮复习情况: 未开始
难度: 
考频: 
备注:
---

# 05 大数定律与中心极限定理
![[26张宇基础30讲（概率论）.pdf#page=130&rect=118,344,428,538|26张宇基础30讲（概率论）, p.130]]

## 05-1 切比雪夫不等式 (Chebyshev's Inequality)

1. **概念**：切比雪夫不等式给出了随机变量取值偏离其数学期望的概率的一个**上界**，**无论随机变量的分布形式如何**。它是一个非常普遍的概率不等式。
2. **公式**：对于任意随机变量 $X$ (只要 $E(X)$ 和 $D(X)$ 存在)，以及任意正数 $\varepsilon > 0$，有：
    $$ P(|X - E(X)| \geq \varepsilon) \leq \frac{D(X)}{\varepsilon^2} $$
    或者等价地，其**对偶形式** (通常更常用，表示偏离期望小于 $\varepsilon$ 的概率下限)：
    $$ P(|X - E(X)| < \varepsilon) \geq 1 - \frac{D(X)}{\varepsilon^2} $$
3. **意义**：
    * 它表明，随机变量的取值偏离其期望的程度越大，其发生的概率就越小。
    * 方差 $D(X)$ 越小，偏离期望的概率就越小，说明数据越集中在期望附近。
4. **应用**：
    * 在不知道随机变量具体分布的情况下，可以用来**估计概率**。
    * 它是**大数定律的理论基础**之一。

## 05-2 依概率收敛 (Convergence in Probability)

1. **概念**：随机变量序列 $\{X_n\}$ 依概率收敛于常数 $a$，是指当 $n$ 足够大时，$X_n$ 取值与 $a$ 的偏差小于任意小的正数 $\varepsilon$ 的概率趋于 $1$。
2. **定义**：若 $\lim_{n \to \infty} P\{|X_n - a| < \varepsilon\} = 1$ (或等价地 $\lim_{n \to \infty} P\{|X_n - a| \ge \varepsilon\} = 0$)，则称随机变量序列 $\{X_n\}$ 依概率收敛于 $a$，记作 $X_n \xrightarrow{P} a$。
3. **意义**：是理解大数定律的基础，描述了**随机变量的"平均行为"趋于稳定**的数学表达。

## 05-3 大数定律 (Laws of Large Numbers) (考研重点理解其结论和条件！)

* **核心思想**：当试验次数足够多时，样本的平均结果会**依概率**趋近于总体的期望值。这解释了为什么我们可以通过大量样本的平均值来估计总体的参数。

### 1. 切比雪夫大数定律 (Chebyshev's Law of Large Numbers)
* **条件**：设随机变量序列 $X_1, X_2, \ldots, X_n$ **相互独立**，且它们都有有限的期望 $E(X_k)=\mu_k$ 和方差 $D(X_k)=\sigma_k^2$。如果存在常数 $C$ 使得 $D(X_k) \le C$ (即方差有界)。
* **结论**：对任意 $\varepsilon > 0$，有
    $$ \lim_{n \to \infty} P\left\{ \left| \frac{1}{n}\sum_{k=1}^n X_k - \frac{1}{n}\sum_{k=1}^n E(X_k) \right| < \varepsilon \right\} = 1 $$
    * **简化版 (常用)**：若 $X_k$ **同分布**，且 $E(X_k)=\mu, D(X_k)=\sigma^2$ 有限，则
        $$ \lim_{n \to \infty} P\left\{ \left| \frac{1}{n}\sum_{k=1}^n X_k - \mu \right| < \varepsilon \right\} = 1 $$
        即 $\bar{X}_n \xrightarrow{P} \mu$。
* **物理意义**：样本均值 $\bar{X}_n$ 依概率收敛于总体期望 $\mu$。这是所有大数定律最常见的形式。

### 2. 伯努利大数定律 (Bernoulli's Law of Large Numbers)
* **条件**：在 $n$ 次独立重复的伯努利试验中，事件 $A$ 发生的次数为 $N_n$ (即 $N_n \sim B(n, p)$)，事件 $A$ 发生的概率为 $p$。
* **结论**：对任意 $\varepsilon > 0$，有
    $$ \lim_{n \to \infty} P\left\{ \left| \frac{N_n}{n} - p \right| < \varepsilon \right\} = 1 $$
    即频率 $\frac{N_n}{n}$ 依概率收敛于概率 $p$。
* **物理意义**：样本频率依概率收敛于总体概率。它是切比雪夫大数定律的特例。

### 3. 辛钦大数定律 (Khinchin's Law of Large Numbers)
* **条件**：设随机变量序列 $X_1, X_2, \ldots, X_n$ **相互独立同分布**，且它们有有限的期望 $E(X_k)=\mu$。
* **结论**：对任意 $\varepsilon > 0$，有
    $$ \lim_{n \to \infty} P\left\{ \left| \frac{1}{n}\sum_{k=1}^n X_k - \mu \right| < \varepsilon \right\} = 1 $$
    即 $\bar{X}_n \xrightarrow{P} \mu$。
* **物理意义**：与切比雪夫大数定律的结论一致，但条件更弱（不需要方差有界，只需要同分布且期望存在）。它是应用最广泛的大数定律之一。

## 05-4 中心极限定理 (Central Limit Theorem, CLT) (考研核心，必考！)

* **核心思想**：当独立同分布的随机变量个数足够多时，它们的**和（或平均值）的分布**趋近于**正态分布**。这是概率论中最著名、最强大的定理之一。

### 1. 独立同分布中心极限定理（列维-林德伯格定理）
* **条件**：设随机变量序列 $X_1, X_2, \ldots, X_n$ **相互独立同分布**，且它们有有限的期望 $E(X_k)=\mu$ 和方差 $D(X_k)=\sigma^2$ (其中 $\sigma^2 > 0$)。
* **结论**：当 $n \to \infty$ 时，随机变量的和 $S_n = \sum_{k=1}^n X_k$ 的标准化变量 $Y_n = \frac{S_n - E(S_n)}{\sqrt{D(S_n)}}$ 的分布函数 $F_{Y_n}(x)$ 趋近于标准正态分布 $N(0,1)$ 的分布函数 $\Phi(x)$。
    $$ Y_n = \frac{\sum_{k=1}^n X_k - n\mu}{\sqrt{n}\sigma} \xrightarrow{D} N(0,1) $$
    即对于任意 $x$， $\lim_{n \to \infty} P\{Y_n \le x\} = \Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-t^2/2} \, dt$。
* **物理意义**：大量独立随机因素的叠加效应趋向于正态分布。这解释了自然界和社会中许多现象服从或近似服从正态分布的原因（例如测量误差、身高分布等）。
* **应用**：当 $n$ 足够大时，可以用正态分布来近似计算 $S_n$ 或 $\bar{X}_n$ 的概率。

### 2. 德莫弗-拉普拉斯定理 (De Moivre-Laplace Theorem)
* **条件**：当二项分布 $Y_n \sim B(n, p)$ 的试验次数 $n$ 很大时。
* **结论**：二项分布的标准化变量 $Z = \frac{Y_n - np}{\sqrt{np(1-p)}}$ 的分布函数趋近于标准正态分布 $N(0,1)$ 的分布函数 $\Phi(x)$。
    $$ \lim_{n \to \infty} P\left\{ \frac{Y_n - np}{\sqrt{np(1-p)}} \le x \right\} = \Phi(x) $$
* **物理意义**：它是中心极限定理的特例，表明当 $n$ 很大时，二项分布可以用正态分布来近似。

## 05-5 其他重要不等式 (数学一/三拓展)

### 1. 马尔可夫不等式 (Markov's Inequality)
* **概念**：比切比雪夫不等式更基础，对任何非负随机变量，给出其取值大于某个正数的概率上限。
* **公式**：对于任意非负随机变量 $X \ge 0$ (只要 $E(X)$ 存在)，以及任意正数 $\varepsilon > 0$，有：
    $$ P(X \geq \varepsilon) \leq \frac{E(X)}{\varepsilon} $$
* **（拓展）高阶矩形式**：对于任意随机变量 $X$ (只要 $E(|X|^\gamma)$ 存在)，以及任意正数 $\varepsilon > 0, \gamma > 0$，有：
    $$ P(|X| \geq \varepsilon) \leq \frac{E(|X|^\gamma)}{\varepsilon^\gamma} $$
    * 当 $\gamma=2$ 时，这就是切比雪夫不等式的前身（对 $Y=(X-E(X))^2$ 应用马尔可夫不等式）。

---
