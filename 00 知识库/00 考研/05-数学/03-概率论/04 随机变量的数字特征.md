---
科目:
课程名称:
tags: []
一轮复习情况: 进行中
二轮复习情况: 未开始
三轮复习情况: 未开始
难度:
考频:
备注:
---

# 04 随机变量的数字特征
## 04-1 一维随机变量的数字特征

### 1. 数学期望 (Expectation / Mean)
* **概念**：数学期望 $E(X)$ 或 $\mu$，表示随机变量 $X$ 的**平均值**，反映取值的**中心位置**。
    * **离散型**：$E(X) = \sum_{k=1}^{\infty} x_k p_k$
    * **连续型**：$E(X) = \int_{-\infty}^{\infty} x f(x) \, dx$
* **性质**：
    1. $E(C) = C$。
    2. $E(aX + b) = aE(X) + b$ (线性性质)。
    3. $E(X + Y) = E(X) + E(Y)$ (**无论 $X, Y$ 是否独立，始终成立！**)。
    4. 如果 $X, Y$ 相互独立，则 $E(XY) = E(X)E(Y)$。

### 2. 方差、标准差 (Variance, Standard Deviation)

* **概念**：方差 $D(X)$ 或 $Var(X)$ 或 $\sigma^2$，表示 $X$ 的取值在其期望附近的**离散程度**。
    * **定义式**：$D(X) = E[(X - E(X))^2]$
    * **计算公式**：$D(X) = E(X^2) - [E(X)]^2$ (**最常用！**)。
    * **标准差**：$\sigma(X) = \sqrt{D(X)}$，与 $X$ 具有相同量纲。
* **性质**：
    1. $D(C) = 0$。
    2. $D(aX + b) = a^2 D(X)$。
    3. $D(X) \geq 0$。
    4. **重点**：如果 $X, Y$ 相                             互独立，则 $D(X \pm Y) = D(X) + D(Y)$。
        * **强调**：如果不独立，则需要考虑协方差项：$D(X \pm Y) = D(X) + D(Y) \pm 2\text{Cov}(X, Y)$。
![[一维连续随机变量分布的期望和方差.png]]
## 04-2 二维随机变量的数字特征

### 1. 数学期望 (对于函数 $Z = g(X, Y)$)

* **概念**：如果 $Z = g(X, Y)$ 是二维随机变量 $(X, Y)$ 的一个函数，那么 $Z$ 也是一个随机变量。它的数学期望为：
    * **离散型**：$E[g(X, Y)] = \sum_{i} \sum_{j} g(x_i, y_j) p_{ij}$。
    * **连续型**：$E[g(X, Y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) f(x, y) \, dx \, dy$。
* **重要应用**：计算 $E(X), E(Y)$，以及协方差和相关系数。**$E(X)$ 也可以通过其边缘密度 $f_X(x)$ 计算：$E(X) = \int_{-\infty}^{\infty} x f_X(x) \, dx$。**

### 2. 协方差与相关系数 (Covariance, Correlation Coefficient)

* **协方差 (Covariance)**：$Cov(X, Y)$，衡量 $X$ 和 $Y$ 之间**线性关系的方向和强度**。
    * **定义式**：$Cov(X, Y) = E[(X - E(X))(Y - E(Y))]$。
    * **计算公式**：$Cov(X, Y) = E(XY) - E(X)E(Y)$ (**最常用！**)。
    * **性质**：
        1. $Cov(X, X) = D(X)$。
        2. $Cov(X, Y) = Cov(Y, X)$。
        3. $Cov(aX + b, cY + d) = ac Cov(X, Y)$。
        4. $D(X + Y) = D(X) + D(Y) + 2Cov(X, Y)$。
        5. **核心**：如果 $X, Y$ 相互独立，则 $Cov(X, Y) = 0$。(但反之不一定成立！)

* **相关系数 (Correlation Coefficient)**：$\rho_{XY}$ 或 $\rho(X, Y)$，将协方差标准化，取值范围在 $[-1, 1]$ 之间。
    * **定义式**：$\rho_{XY} = \frac{Cov(X, Y)}{\sqrt{D(X)D(Y)}}$。
    * **性质**：
        1. $-1 \leq \rho_{XY} \leq 1$。
        2. $\rho_{XY} = 0$ 表示 $X, Y$ **不相关** (无线性关系)。
        3. $|\rho_{XY}| = 1$ 表示 $X, Y$ 之间存在**完全线性关系** ($Y = aX + b, a \ne 0$)。

---

### 3. 矩与高阶数字特征
#### 1. 矩 (Moments)
* **概念**：矩是期望的推广，能够更全面地描述随机变量的分布特征，如中心位置、离散程度、偏态和峰态。
 (1) $k$ 阶原点矩 (k-th Raw Moment)
* **一维随机变量 $X$**：$E(X^k) = \int_{-\infty}^{\infty} x^k f(x) \, dx$ (连续型) 或 $\sum_i x_i^k p_i$ (离散型)。
    * $k=1$ 时即为数学期望 $E(X)$。
* **二维随机变量 $(X, Y)$**：$E(X^k Y^l) = \iint x^k y^l f(x,y) \, dx \, dy$。
 (2) $k$ 阶中心矩 (k-th Central Moment)
* **一维随机变量 $X$**：$\mu_k = E[(X - E(X))^k] = \int_{-\infty}^{\infty} (x - E(X))^k f(x) \, dx$。
    * $k=1$ 时 $\mu_1 = 0$。
    * $k=2$ 时 $\mu_2 = D(X)$ (方差)。
* **二维随机变量 $(X, Y)$**：$E[(X - E(X))^k (Y - E(Y))^l]$。

#### 2. 协方差矩阵 (Covariance Matrix)
* **概念**：对于 $n$ 维随机向量 $\mathbf{X} = (X_1, X_2, \ldots, X_n)^T$，其协方差矩阵是一个对称矩阵，描述了各个分量之间的协方差关系。
* **定义**：设 $\mathbf{X} = (X_1, X_2, \ldots, X_n)^T$，则协方差矩阵为 $\mathbf{\Sigma} = (\sigma_{ij})_{n \times n}$，其中：
    $$ \sigma_{ij} = \text{Cov}(X_i, X_j) = E[(X_i - E(X_i))(X_j - E(X_j))] $$
* **性质**：
    1. **对称性**：$\mathbf{\Sigma}^T = \mathbf{\Sigma}$ (因为 $\text{Cov}(X_i, X_j) = \text{Cov}(X_j, X_i)$)。
    2. **主对角线元素**：$\sigma_{ii} = \text{Cov}(X_i, X_i) = D(X_i)$ (是各分量的方差)。
    3. **半正定性**：协方差矩阵是**非负定**的（半正定的）。

#### 3. 偏态系数与峰态系数
 (1) 偏态系数 (Skewness Coefficient) $C_s$
* **概念**：衡量随机变量分布的**对称性**，即分布的偏斜程度。
* **公式**：$C_s = \frac{\mu_3}{\sigma^3} = \frac{E[(X - E(X))^3]}{[D(X)]^{3/2}}$。
* **物理意义** (看你的图示！)：
    * $C_s > 0$：分布右偏（尾巴在右边，平均值在众数右边）。
    * $C_s < 0$：分布左偏（尾巴在左边，平均值在众数左边）。
    * $C_s = 0$：分布对称（如正态分布）。
![[偏态系数.png]]
 (2) 峰态系数 (Kurtosis Coefficient) $C_e$
* **概念**：衡量随机变量分布的**平坦度或尖峭程度**，即分布在均值附近的集中程度和尾部的厚重程度。
* **公式**：$C_e = \frac{\mu_4}{\sigma^4} = \frac{E[(X - E(X))^4]}{[D(X)]^2}$。
* **物理意义**：
    * $C_e$ 越大：分布越尖峭，尾部越厚（峰度高）。
    * $C_e$ 越小：分布越平坦，尾部越轻（峰度低）。
    * **正态分布的峰态系数为 $3$**（有时会定义为 $C_e-3$，使正态分布的峰态系数为 $0$）。

---

## 04-3 条件期望与重期望公式
* **联合概率密度函数的构建**：
    * 如果已知边缘密度 $f_X(x)$ 和条件密度 $f_{Y|X}(y|x)$，那么联合密度为：
        $$ f(x, y) = f_{Y|X}(y|x) f_X(x) $$
    * 通过此联合密度，可以计算 $E[g(X, Y)] = \iint g(x,y)f(x,y)dxdy$。
* **条件期望 \(E(Y|X=x)\)**：
    * 顾名思义，它表示在已知 $X=x$ 的条件下，$Y$ 的期望。
    * **计算方法**：
        * **离散型**：$E(Y|X=x_i) = \sum_j y_j P(Y=y_j|X=x_i)$
        * **连续型**：$E(Y|X=x) = \int_{-\infty}^{\infty} y f_{Y|X}(y|x) \, dy$
    * **注意**：$E(Y|X=x)$ 的结果是一个关于 $x$ 的函数。当 $x$ 替换为随机变量 $X$ 时，它就变成了随机变量 $E(Y|X)$。
* **重期望公式 (Law of Total Expectation)**：
    * 这个公式能够帮助我们通过条件期望来计算一个随机变量的期望，或者一个函数的期望，尤其在随机变量之间存在依赖关系时非常有用，避免了直接求联合分布的麻烦。
    * **计算 $E(Y)$**：
        $$ E(Y) = E[E(Y|X)] = \int_{-\infty}^{\infty} E(Y|X=x) f_X(x) \, dx $$
        * **两步走**：先计算内层期望 $E(Y|X=x)$（得到一个关于 $x$ 的函数），再对这个函数关于 $X$ 的边缘密度 $f_X(x)$ 求期望（积分）。
    * **计算 $E[g(X,Y)]$** (例如 $E(XY)$)：
        $$ E[g(X, Y)] = E[E(g(X, Y)|X)] = \int_{-\infty}^{\infty} E[g(X, Y)|X=x] f_X(x) \, dx $$
        * **对于 $E(XY)$ 的特殊情况**：
            * 在 $X=x$ 的条件下，$x$ 可以被视为常数，所以 $E(XY|X=x) = x E(Y|X=x)$。
            * 因此，$E(XY) = \int_{-\infty}^{\infty} x E(Y|X=x) f_X(x) \, dx$。
    * **核心优势**：当直接计算联合积分 $\iint g(x,y)f(x,y)dxdy$ 比较困难，或者题目直接给出了条件分布时，重期望公式能大大简化计算流程，是解决这类问题的"金钥匙"！

## 04-4 独立性与不相关性的判断、切比雪夫不等式

### 1. 用分布判断独立性
* **概念**：两个随机变量 $X$ 和 $Y$ 相互独立，意味着一个变量的取值不会影响另一个变量的取值。
* **充要条件**：
    * **离散型**：$P(X = x_i, Y = y_j) = P(X = x_i) P(Y = y_j)$ 对所有 $i, j$ 成立。
    * **连续型**：$f(x, y) = f_X(x) f_Y(y)$ 对所有 $x, y$ 成立。
    * **分布函数**：$F(x, y) = F_X(x) F_Y(y)$ 对所有 $x, y$ 成立。

### 2. 用数字特征判定不相关性
* **不相关**：如果 $Cov(X, Y) = 0$，则称 $X$ 和 $Y$ 不相关。
* **重要关系**：
    * **独立 $\Rightarrow$ 不相关**：如果 $X$ 和 $Y$ 相互独立，那么它们一定不相关 ($Cov(X, Y) = 0$)。
    * **不相关 $\nRightarrow$ 独立**：不相关只意味着没有线性关系，但可能存在非线性关系。所以，不相关不一定意味着独立。
    * **特例**：对于**二维正态分布**，独立与不相关是等价的。

### 3. 切比雪夫不等式 (Chebyshev's Inequality)
* **概念**：切比雪夫不等式给出了随机变量取值偏离其数学期望的概率的一个**上界**，无论随机变量的分布形式如何。它是一个非常普遍的概率不等式。
* **公式**：对于任意随机变量 $X$ (只要 $E(X)$ 和 $D(X)$ 存在)，以及任意正数 $\epsilon > 0$，有：
    $$ P(|X - E(X)| \geq \epsilon) \leq \frac{D(X)}{\epsilon^2} $$
    或者等价地：
    $$ P(|X - E(X)| < \epsilon) \geq 1 - \frac{D(X)}{\epsilon^2} $$
* **意义**：它表明，随机变量的取值偏离其期望的程度越大，其发生的概率就越小。方差越小，偏离期望的概率就越小。
* **应用**：在不知道随机变量具体分布的情况下，可以用来估计概率。它是大数定律的理论基础之一。

---
