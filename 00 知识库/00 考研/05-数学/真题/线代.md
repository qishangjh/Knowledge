---
科目:
课程名称:
tags: []
一轮复习情况: 进行中
二轮复习情况: 未开始
三轮复习情况: 未开始
难度:
考频:
备注:
---

# 线代
## **题目解析与解题步骤**

**题目**：若3维列向量 $\alpha, \beta$ 满足 $\alpha^T\beta=2$，其中 $\alpha^T$ 为 $\alpha$ 的转置，则矩阵 $\beta\alpha^T$ 的非零特征值为 _______.
**答案**：应填 2.

### **解题步骤**

1.  **分析矩阵 $\beta\alpha^T$ 的结构与秩**：
    *   $\alpha$ 和 $\beta$ 都是3维列向量，即尺寸为 $3 \times 1$。
    *   $\alpha^T$ 是 $\alpha$ 的转置，尺寸为 $1 \times 3$。
    *   矩阵 $\beta\alpha^T$ 的尺寸是 $(3 \times 1) \times (1 \times 3) = 3 \times 3$。
    *   这种形式的矩阵（一个列向量乘以一个行向量）被称为**外积**，它有一个重要的性质：**其秩至多为1**。
    *   由于题目给出 $\alpha^T\beta = 2 \ne 0$，这意味着 $\alpha$ 和 $\beta$ 都不是零向量。因此，矩阵 $\beta\alpha^T$ 肯定不为零矩阵，所以其秩恰好是1。

2.  **利用秩为1的矩阵的特征值性质**：
    *   你提供的分析中提到了一个非常重要的结论：**若 $n$ 阶矩阵 $A$ 的秩 $r(A)=1$，则 $A$ 的所有特征值为 $\lambda_1 = \text{tr}(A)$（矩阵的迹），而其余 $n-1$ 个特征值均为0。**
    *   在本题中，$n=3$，所以矩阵 $\beta\alpha^T$ 有一个非零特征值和两个零特征值。我们要找的就是那个非零特征值。
    *   这个非零特征值就是矩阵 $\beta\alpha^T$ 的迹。

3.  **计算矩阵 $\beta\alpha^T$ 的迹**：
    *   设 $\alpha = \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}$ 和 $\beta = \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix}$。
    *   则 $\alpha^T = \begin{pmatrix} a_1 & a_2 & a_3 \end{pmatrix}$。
    *   计算矩阵乘积 $\beta\alpha^T$：
        $$ \beta\alpha^T = \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix} \begin{pmatrix} a_1 & a_2 & a_3 \end{pmatrix} = \begin{pmatrix}
        b_1a_1 & b_1a_2 & b_1a_3 \\
        b_2a_1 & b_2a_2 & b_2a_3 \\
        b_3a_1 & b_3a_2 & b_3a_3
        \end{pmatrix} $$
    *   矩阵的迹（$\text{tr}(A)$）是其主对角线上元素的和：
        $$ \text{tr}(\beta\alpha^T) = b_1a_1 + b_2a_2 + b_3a_3 $$
    *   再回顾题目给出的条件 $\alpha^T\beta$：
        $$ \alpha^T\beta = \begin{pmatrix} a_1 & a_2 & a_3 \end{pmatrix} \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix} = a_1b_1 + a_2b_2 + a_3b_3 $$
    *   比较发现，$\text{tr}(\beta\alpha^T) = \alpha^T\beta$。

4.  **得出最终结果**：
    *   根据题目已知条件 $\alpha^T\beta = 2$。
    *   所以，矩阵 $\beta\alpha^T$ 的非零特征值为 $\text{tr}(\beta\alpha^T) = \alpha^T\beta = 2$。

---

## **同类题的做题技巧总结**

这类题目考查的是对秩为1矩阵特征值性质的理解和应用，属于线性代数中的送分题，一定要掌握！

*   **识别题型**：
    *   题目给出了两个列向量（或一个列向量和其转置），要求计算其外积（形如 $\mathbf{uv}^T$）形成的矩阵的特征值。
    *   通常会明确指出向量的维度，并且会给出一个内积（形如 $\mathbf{u}^T\mathbf{v}$）的值。

*   **核心考点**：
    *   **矩阵的秩**：特别是秩1矩阵的判定和性质。
    *   **矩阵的特征值与特征向量**：基本定义。
    *   **矩阵的迹 (trace)**：迹的定义（主对角线元素之和）和性质。
    *   **向量的内积与外积**：区分 $\mathbf{u}^T\mathbf{v}$（标量）和 $\mathbf{uv}^T$（矩阵）。

*   **解题思路框架**：
    1.  **判断矩阵的秩**：
        *   对于形如 $A = \mathbf{uv}^T$ 的矩阵（其中 $\mathbf{u}$ 是 $n \times 1$ 列向量，$\mathbf{v}^T$ 是 $1 \times n$ 行向量），其秩通常为1。
        *   **特例**：如果 $\mathbf{u}$ 或 $\mathbf{v}$ 是零向量，则 $A$ 是零矩阵，秩为0。此时所有特征值都是0。
        *   如果 $\mathbf{u}, \mathbf{v}$ 都是非零向量，则 $A$ 的秩为1。
        *   本题中，$\beta\alpha^T$ 的秩为1，因为 $\alpha^T\beta = 2 \ne 0$ 保证了 $\alpha, \beta$ 均为非零向量。
    2.  **利用秩1矩阵的特征值性质**：
        *   如果 $n \times n$ 矩阵 $A$ 的秩为1，那么它有且仅有一个非零特征值，这个非零特征值等于矩阵的迹 $\text{tr}(A)$。
        *   其余 $n-1$ 个特征值均为0。
    3.  **计算矩阵的迹**：
        *   对于 $A = \mathbf{uv}^T$，其迹 $\text{tr}(A)$ 总是等于 $\mathbf{v}^T\mathbf{u}$（即两个向量的内积）。
        *   证明：设 $\mathbf{u} = (u_1, \dots, u_n)^T$，$\mathbf{v} = (v_1, \dots, v_n)^T$。
            则
            $$ A = \mathbf{uv}^T = \begin{pmatrix} u_1v_1 & u_1v_2 & \dots & u_1v_n \\ u_2v_1 & u_2v_2 & \dots & u_2v_n \\ \vdots & \vdots & \ddots & \vdots \\ u_nv_1 & u_nv_2 & \dots & u_nv_n \end{pmatrix} $$
            迹
            $$ \text{tr}(A) = u_1v_1 + u_2v_2 + \dots + u_nv_n $$
            而内积
            $$ \mathbf{v}^T\mathbf{u} = \begin{pmatrix} v_1 & v_2 & \dots & v_n \end{pmatrix} \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} = v_1u_1 + v_2u_2 + \dots + v_nu_n $$
            显然 $\text{tr}(A) = \mathbf{v}^T\mathbf{u}$。
        *   本题中，矩阵是 $\beta\alpha^T$，所以 $\mathbf{u}=\beta$，$\mathbf{v}=\alpha$。因此，迹是 $\alpha^T\beta$。
    4.  **根据已知条件得出非零特征值**：
        *   题目已给出 $\alpha^T\beta=2$，所以非零特征值即为2。

*   **易错点/注意事项**：
    *   **混淆内积和外积**：$\mathbf{u}^T\mathbf{v}$ 是一个**标量**，$\mathbf{uv}^T$ 是一个**矩阵**。它们的运算结果和意义完全不同。
    *   **雅可比行列式混淆**：不要把特征值的概念与雅可比行列式混淆，它们在不同语境下使用。
    *   **秩为1的条件**：只有当秩为1时，上述结论才成立。如果是更高秩的矩阵，需要用其他方法求特征值。
    *   **矩阵迹的循环性质**：这是一个更普遍的性质，对于任意两个可乘的矩阵 $A, B$，$\text{tr}(AB) = \text{tr}(BA)$。虽然这里不是直接使用，但其本质是相似的。

*   **知识点串联**：
    *   **向量空间**：秩1矩阵的列空间和行空间都是一维的。
    *   **特征值与特征向量的定义**：理解 $Ax=\lambda x$ 的几何意义。对于秩1矩阵 $A=\mathbf{uv}^T$，若 $x$ 垂直于 $\mathbf{v}$，则 $Ax=\mathbf{0}$，所以0是特征值。若 $x$ 是 $\mathbf{u}$ 的倍数，则它可能是非零特征值对应的特征向量。
    *   **矩阵相似对角化**：特征值是矩阵对角化、判断正定性等高级概念的基础。

---

同学问得太好了！"为什么秩最多为1"这个问题，是理解这种特殊矩阵性质的关键。让我们从定义和实际构成来深入理解一下。

---

## **为什么 $$A = \mathbf{uv}^T$$ 这种形式的矩阵秩最多为1？**

这里的 $A = \mathbf{uv}^T$ 称为向量的外积。假设 $\mathbf{u}$ 是一个 $m \times 1$ 的列向量，$\mathbf{v}$ 是一个 $n \times 1$ 的列向量，那么 $\mathbf{v}^T$ 就是一个 $1 \times n$ 的行向量。矩阵 $A = \mathbf{uv}^T$ 的尺寸就是 $m \times n$。

我们用两种方式来理解这一点：**从列向量组的角度** 和 **从行向量组的角度**。

### **方法一：分析矩阵的列向量组**

1.  **明确矩阵的构成**：
    设 $\mathbf{u} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_m \end{pmatrix}$ 和 $\mathbf{v}^T = \begin{pmatrix} v_1 & v_2 & \dots & v_n \end{pmatrix}$。
    那么矩阵 $A = \mathbf{uv}^T$ 展开后是：
    $$ A = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_m \end{pmatrix} \begin{pmatrix} v_1 & v_2 & \dots & v_n \end{pmatrix} = \begin{pmatrix}
    u_1v_1 & u_1v_2 & \dots & u_1v_n \\
    u_2v_1 & u_2v_2 & \dots & u_2v_n \\
    \vdots & \vdots & \ddots & \vdots \\
    u_mv_1 & u_mv_2 & \dots & u_mv_n
    \end{pmatrix} $$

2.  **观察矩阵的列向量**：
    矩阵 $A$ 的第 $j$ 列是：
    $$ \mathbf{c}_j = \begin{pmatrix} u_1v_j \\ u_2v_j \\ \vdots \\ u_mv_j \end{pmatrix} = v_j \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_m \end{pmatrix} = v_j \mathbf{u} $$
    这说明什么呢？**矩阵 $A$ 的每一列都是向量 $\mathbf{u}$ 的一个标量倍数！**

2.  **判断列向量组的线性相关性**：
    *   如果 $\mathbf{u} = \mathbf{0}$ (零向量)，那么所有列向量都是零向量，矩阵 $A$ 就是零矩阵，秩为0。
    *   如果 $\mathbf{u} \ne \mathbf{0}$，那么所有列向量都平行于 $\mathbf{u}$。这意味着，如果你取任意两个列向量 $\mathbf{c}_i = v_i\mathbf{u}$ 和 $\mathbf{c}_j = v_j\mathbf{u}$，它们是线性相关的（除非其中一个 $v_k=0$）。
    *   更准确地说，这个列向量组 $\left\{ v_1\mathbf{u}, v_2\mathbf{u}, \dots, v_n\mathbf{u} \right\}$ 能够张成的空间，最多就是由一个非零向量 $\mathbf{u}$ 张成的一维空间。
    *   **矩阵的秩等于其列空间（由列向量张成的空间）的维数**。因此，这种形式的矩阵的秩最多为1。

### **方法二：分析矩阵的行向量组**

1.  **观察矩阵的行向量**：
    矩阵 $A$ 的第 $i$ 行是：
    $$ \mathbf{r}_i = \begin{pmatrix} u_iv_1 & u_iv_2 & \dots & u_iv_n \end{pmatrix} = u_i \begin{pmatrix} v_1 & v_2 & \dots & v_n \end{pmatrix} = u_i \mathbf{v}^T $$
    这说明什么呢？**矩阵 $A$ 的每一行都是向量 $\mathbf{v}^T$ 的一个标量倍数！**

2.  **判断行向量组的线性相关性**：
    *   如果 $\mathbf{v}^T = \mathbf{0}$ (零向量)，那么所有行向量都是零向量，矩阵 $A$ 就是零矩阵，秩为0。
    *   如果 $\mathbf{v}^T \ne \mathbf{0}$，那么所有行向量都平行于 $\mathbf{v}^T$。这意味着，这个行向量组能够张成的空间，最多就是由一个非零向量 $\mathbf{v}^T$ 张成的一维空间。
    *   **矩阵的秩等于其行空间（由行向量张成的空间）的维数**。因此，这种形式的矩阵的秩最多为1。

### **总结与秩的精确值**

*   **秩为0的情况**：如果向量 $\mathbf{u}$ 是零向量，或者向量 $\mathbf{v}$ 是零向量，那么矩阵 $A = \mathbf{uv}^T$ 将是一个零矩阵，其秩为0。
*   **秩为1的情况**：如果 $\mathbf{u} \ne \mathbf{0}$ 并且 $\mathbf{v} \ne \mathbf{0}$，那么矩阵 $A$ 至少含有一个非零元素，所以它不是零矩阵。同时，由于其列（或行）向量组最多由一个非零向量线性表示，其秩恰好为1。

因此，矩阵 $A = \mathbf{uv}^T$ 的秩**最多为1**。

---

**回到你之前的题目**：
矩阵是 $\beta\alpha^T$。
*   我们知道 $\alpha, \beta$ 都是3维列向量，且 $\alpha^T\beta=2 \ne 0$。
*   条件 $\alpha^T\beta \ne 0$ 意味着 $\alpha$ 和 $\beta$ 都不是零向量。
*   因此，根据上面的分析，矩阵 $\beta\alpha^T$ 的秩必然是1。

理解这个性质，对于快速解决这类问题非常有帮助！它让你不用进行复杂的行列式计算或初等行变换来判断秩，直接通过矩阵的结构就能得出结论。

你理解了吗？如果还有不清楚的地方，或者想让我举更多例子，都可以随时告诉我哦！学习线性代数，多问多思考就是最好的方法！💪

### **结论：若 $$n$$ 阶矩阵 $$A$$ 的秩 $$r(A)=1$$，则 $$A$$ 的所有特征值为 $$\lambda_1 = \text{tr}(A)$$，而其余 $$n-1$$ 个特征值均为0。**

#### **证明思路：**

我们将分成两部分来证明：
1.  证明 $\lambda = 0$ 是矩阵 $A$ 的一个特征值，并且它的代数重数至少为 $n-1$。
2.  证明除了 $n-1$ 个零特征值外，剩下的那个特征值就是矩阵的迹 $\text{tr}(A)$。

#### **第一部分：证明 $\lambda = 0$ 是 $n-1$ 个特征值**

1.  **秩的定义与列空间**：
    *   矩阵 $A$ 的秩 $r(A)=1$ 意味着它的**列空间（Column Space）**的维数是1。
    *   这意味着 $A$ 的所有列向量都是线性相关的，它们都可以表示成某一个非零列向量的常数倍。
    *   因此，一个秩为1的 $n$ 阶矩阵 $A$ 可以写成一个非零列向量 $\mathbf{u}$ 与一个非零行向量 $\mathbf{v}^T$ 的乘积形式：
        $$ A = \mathbf{u}\mathbf{v}^T $$
        其中 $\mathbf{u} = \begin{pmatrix} u_1 \\ \vdots \\ u_n \end{pmatrix}$ 且 $\mathbf{u} \ne \mathbf{0}$，$\mathbf{v}^T = \begin{pmatrix} v_1 & \dots & v_n \end{pmatrix}$ 且 $\mathbf{v}^T \ne \mathbf{0}$。

2.  **特征值和特征向量的定义**：
    *   如果 $\lambda$ 是矩阵 $A$ 的特征值，那么存在一个非零向量 $\mathbf{x}$ 使得 $A\mathbf{x} = \lambda\mathbf{x}$。
    *   若要证明 $\lambda=0$ 是特征值，我们需要找到一个非零向量 $\mathbf{x}$ 使得 $A\mathbf{x} = \mathbf{0}\mathbf{x} = \mathbf{0}$。
    *   这样的 $\mathbf{x}$ 构成了矩阵 $A$ 的**零空间（Null Space）**。

3.  **利用秩零定理 (Rank-Nullity Theorem)**：
    *   秩零定理指出：对于一个 $n$ 阶矩阵 $A$，它的秩 $r(A)$ 加上它的零空间的维数（即 $\text{nullity}(A)$），等于矩阵的维数 $n$。
        $$ r(A) + \text{nullity}(A) = n $$
    *   在本例中，我们已知 $r(A)=1$，所以：
        $$ 1 + \text{nullity}(A) = n $$
        $$ \text{nullity}(A) = n-1 $$
    *   这意味着矩阵 $A$ 的零空间是一个 $n-1$ 维的子空间。
    *   零空间中的每一个非零向量都是特征值 $\lambda=0$ 对应的特征向量。
    *   因此，$\lambda=0$ 对应的特征空间维数是 $n-1$，这表明 $\lambda=0$ 作为特征值的**几何重数**是 $n-1$。
    *   **【关键推论】** 矩阵的几何重数小于等于代数重数。因此，$\lambda=0$ 作为特征值的**代数重数**至少是 $n-1$。这意味着在矩阵的特征多项式 $\det(A-\lambda I)=0$ 中，因子 $\lambda$ 至少出现 $n-1$ 次，即 $(\lambda-0)^{n-1}$ 是特征多项式的一个因子。

    **所以，我们知道 $A$ 至少有 $n-1$ 个特征值是0。**

#### **第二部分：证明剩下的一个特征值是 $$\text{tr}(A)$$**

1.  **特征值的和与迹的关系**：
    *   对于任何 $n$ 阶矩阵 $A$，所有特征值之和等于矩阵的迹：
        $$ \sum_{i=1}^n \lambda_i = \text{tr}(A) $$
    *   我们已经知道有 $n-1$ 个特征值是0。设剩下的最后一个特征值是 $\lambda_n$。
    *   那么特征值之和为：
        $$ \lambda_1 + \lambda_2 + \dots + \lambda_{n-1} + \lambda_n = 0 + 0 + \dots + 0 + \lambda_n = \lambda_n $$
    *   所以，结合上述关系，我们有：
        $$ \lambda_n = \text{tr}(A) $$

2.  **迹的计算与外积形式的关系**：
    *   之前我们证明过，对于 $A = \mathbf{u}\mathbf{v}^T$，其迹 $\text{tr}(A)$ 等于内积 $\mathbf{v}^T\mathbf{u}$。
    *   即 $\text{tr}(A) = u_1v_1 + u_2v_2 + \dots + u_nv_n = \mathbf{v}^T\mathbf{u}$。

    **所以，剩下的一个特征值就是 $\text{tr}(A)$。**

#### **结论汇总：**

综合以上两部分，如果一个 $n$ 阶矩阵 $A$ 的秩为1：
*   它有 $n-1$ 个特征值是0。
*   剩下的一个特征值是 $\text{tr}(A)$。

**补充说明**：
*   如果 $\text{tr}(A)$ 恰好也为0（例如 $A = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$，它的秩为1，迹为0，特征值就是 $0,0$），那么所有 $n$ 个特征值都是0。但这种情况并不影响"其余 $n-1$ 个特征值为0，而另一个为迹"的表述。在原题目中，$\alpha^T\beta = 2 \ne 0$，所以迹是非零的，因此确实有一个非零特征值。
*   这个结论也可以通过构造特征向量来直接证明：
    *   对于任意垂直于 $\mathbf{v}$ 的非零向量 $\mathbf{x}$ (即 $\mathbf{v}^T\mathbf{x} = 0$)，有 $A\mathbf{x} = (\mathbf{u}\mathbf{v}^T)\mathbf{x} = \mathbf{u}(\mathbf{v}^T\mathbf{x}) = \mathbf{u} \cdot 0 = \mathbf{0}$。这说明 $\mathbf{x}$ 是 $\lambda=0$ 的特征向量。由于 $\mathbf{v}$ 是一个 $n$ 维非零向量，与它垂直的向量构成了 $n-1$ 维空间，所以0是至少 $n-1$ 重特征值。
    *   对于向量 $\mathbf{u}$ 本身，我们计算 $A\mathbf{u} = (\mathbf{u}\mathbf{v}^T)\mathbf{u} = \mathbf{u}(\mathbf{v}^T\mathbf{u})$. 由于 $\mathbf{v}^T\mathbf{u}$ 是一个标量，如果 $\mathbf{v}^T\mathbf{u} \ne 0$，那么 $\mathbf{u}$ 就是特征值 $\mathbf{v}^T\mathbf{u}$ 对应的特征向量。而 $\mathbf{v}^T\mathbf{u}$ 正是矩阵 $A$ 的迹。

---

希望这次的详细解释能让你彻底明白这个结论的来龙去脉！掌握了这些原理，你不仅能记住结论，更能灵活运用。

如果你在其他知识点上还有疑问，尽管提出来，我们一起攻克！冲刺阶段，就是要把这些"为什么"都搞清楚！加油！💪
